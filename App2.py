# -*- coding: utf-8 -*-
# Arabic CX Dashboard (3 Dimensions) â€” Streamlit
# Files expected in the same folder:
#   - MN.csv                          â† raw survey data
#   - Digital_Data_tables.xlsx         â† lookup/metadata tables
#
# Run:
#   streamlit run Arabic_Dashboard.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io, re
from datetime import datetime
from pathlib import Path

USER_KEYS = {
    "Ø¨Ù„Ø¯ÙŠØ© Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "password": st.secrets["users"]["MN"],
        "role": "center",
        "file": "MN.csv"
    },
    "Ù…Ø­Ø§ÙƒÙ… Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "password": st.secrets["users"]["CR"],
        "role": "center",
        "file": "CR.csv"
    },
    "Ø§Ù„Ù†ÙŠØ§Ø¨Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "password": st.secrets["users"]["PR"],
        "role": "center",
        "file": "PR.csv"
    },
    "Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©": {
        "password": st.secrets["users"]["EC"],
        "role": "center",
        "file": "EC.csv"
    },
    
    "Ù‡ÙŠØ¦Ø© Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„ØªÙ†Ù…ÙŠØ©": {
        "password": st.secrets["users"]["EN"],
        "role": "center",
        "file": "EN.csv"
    },
    "Ø­ÙƒÙˆÙ…Ø© Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "password": st.secrets["users"]["GS"],
        "role": "admin",
        "file": "Centers_Master.csv"   # ØºÙŠÙ‘Ø± Ø§Ù„Ø§Ø³Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ù…Ù„Ù Ù…Ø®ØªÙ„Ù Ù„Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
    }
}

# =========================================================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© + Ø§ØªØ¬Ø§Ù‡ RTL
# =========================================================
st.set_page_config(page_title="ØªÙ‚Ø±ÙŠØ± ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…ØªØ¹Ø§Ù…Ù„ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© 2025", layout="wide")
PASTEL = px.colors.qualitative.Pastel

# Ø´Ø¹Ø§Ø± Ø£Ø¹Ù„Ù‰ Ø§Ù„ØµÙØ­Ø© (Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ø¥Ø°Ø§ Ø±ØºØ¨Øª)
LOGO_URL = "https://raw.githubusercontent.com/gsecrak/rakdcx2025/main/assets/mini_header3.png"
st.markdown(f"""
    <div style="text-align:center; margin-top:-40px;">
        <img src="{LOGO_URL}" alt="Logo" style="width:950px; max-width:95%; height:auto;">
    </div>
    <hr style="margin-top:20px; margin-bottom:10px;">
""", unsafe_allow_html=True)

# =========================================================
# âœ… RTL Ù…Ø¶Ø¨ÙˆØ·: Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© RTLØŒ Ù„ÙƒÙ† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ø±Ø³ÙˆÙ…Ø§Øª ØªØ¨Ù‚Ù‰ Ø³Ù„ÙŠÙ…Ø© (LTR)
# =========================================================
st.markdown("""
<style>
/* =========================================
   1) RTL Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© (Ø§Ù„Ù†ØµÙˆØµ/Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø±/Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†)
========================================= */
[data-testid="stAppViewContainer"],
[data-testid="block-container"],
[data-testid="stSidebar"]{
    direction: rtl !important;
    text-align: right !important;
    font-family: "Tajawal","Cairo","Segoe UI", sans-serif !important;
}

[data-testid="stAppViewContainer"] *,
[data-testid="stSidebar"] *{
    direction: rtl !important;
    text-align: right !important;
}

/* Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ù†ØµÙˆØµ */
h1, h2, h3, h4, h5, h6, p, label, span, li{
    direction: rtl !important;
    text-align: right !important;
}

/* Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ */
[data-baseweb="input"] input,
[data-baseweb="textarea"] textarea{
    direction: rtl !important;
    text-align: right !important;
}

/* Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø© */
[data-baseweb="select"] *{
    direction: rtl !important;
    text-align: right !important;
}

/* =========================================
   2) Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª: ØªØ¨Ø¯Ø£ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ø¨Ø¯ÙˆÙ† Ù‚Ù„Ø¨ Ø§Ù„ØªØ±ØªÙŠØ¨
   (Ù…Ù‡Ù… Ø¬Ø¯Ù‹Ø§: Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù… row-reverse)
========================================= */
.stTabs [data-baseweb="tab-list"]{
    direction: rtl !important;
    display: flex !important;
    justify-content: flex-start !important; /* Ù…Ø¹ RTL: Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙŠÙ…ÙŠÙ† Ø¨Ø¯ÙˆÙ† Ù‚Ù„Ø¨ Ø§Ù„ØªØ±ØªÙŠØ¨ */
    width: 100% !important;
}

.stTabs [data-baseweb="tab"] > div{
    direction: rtl !important;
    text-align: right !important;
}

.stDownloadButton, .stButton > button{
    font-weight: 600;
}

/* =========================================
   3) Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ (DataFrame/Table) Ù…Ù† RTL
   Ø¹Ø´Ø§Ù† ØªØ±Ø¬Ø¹ ÙˆØ§Ø¶Ø­Ø© Ù…Ø«Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚
========================================= */
[data-testid="stDataFrame"],
[data-testid="stDataFrame"] *,
.stDataFrame, .stDataFrame *,
.stTable, .stTable *{
    direction: ltr !important;
    text-align: left !important;
}

/* =========================================
   4) Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ…Ø§Øª (Plotly) Ù…Ù† RTL
   Ù„Ù…Ù†Ø¹ ØªØ¯Ø§Ø®Ù„ Ù†Øµ x Ù…Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØªØºØ·ÙŠØ© Ø§Ù„Ù€ legend
========================================= */
[data-testid="stPlotlyChart"],
[data-testid="stPlotlyChart"] *{
    direction: ltr !important;
    text-align: left !important;
}

/* Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ Ù†ØµÙˆØµ SVG ØªØªØ£Ø«Ø± Ø¨Ù…Ø­Ø§Ø°Ø§Ø© RTL */
[data-testid="stPlotlyChart"] svg,
[data-testid="stPlotlyChart"] svg *{
    direction: ltr !important;
    unicode-bidi: plaintext !important;
}

</style>
""", unsafe_allow_html=True)

# Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø¬Ù‡Ø§Øª ÙˆØ§Ù„Ù…Ù„ÙØ§Øª
ENTITIES = {
    "Ø¨Ù„Ø¯ÙŠØ© Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "csv": "MN.csv",
        "xlsx": "Data_tables_MN.xlsx",
    },
    "Ù…Ø­Ø§ÙƒÙ… Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "csv": "CR.csv",
        "xlsx": "Data_tables_CR.xlsx",
    },
    "Ø§Ù„Ù†ÙŠØ§Ø¨Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "csv": "PR.csv",
        "xlsx": "Data_tables_PR.xlsx",
    },
    "Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©": {
        "csv": "EC.csv",
        "xlsx": "Data_tables_EC.xlsx",
    },
     "Ù‡ÙŠØ¦Ø© Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„ØªÙ†Ù…ÙŠØ©": {
        "csv": "EN.csv",
        "xlsx": "Data_tables_EN.xlsx",
    },
     # ğŸ‘‡ Ø¬Ù‡Ø© Ø§Ù„Ø£Ø¯Ù…Ù† (ØªØ¬Ù…ÙŠØ¹ ÙƒÙ„ Ø§Ù„Ø¬Ù‡Ø§Øª)
    "Ø­ÙƒÙˆÙ…Ø© Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "csv": "Centers_Master.csv",         # Ù„Ù† Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§
        "xlsx": "Data_tables_MASTER.xlsx",        # Ù„Ù† Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§
    },
}

# =========================================================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# =========================================================
def load_data(csv_name: str, xlsx_name: str):
    # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    df = pd.read_csv(csv_name, encoding="utf-8", low_memory=False)
    df.columns = [c.strip().upper() for c in df.columns]
    df.columns = [c.replace('DIM', 'Dim') for c in df.columns]

    # Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙˆØµÙÙŠØ©
    lookup_catalog = {}
    xls_path = Path(xlsx_name)
    if xls_path.exists():
        xls = pd.ExcelFile(xls_path)
        for sheet in xls.sheet_names:
            tbl = pd.read_excel(xls, sheet_name=sheet)
            tbl.columns = [str(c).strip().upper() for c in tbl.columns]
            lookup_catalog[sheet.strip().upper()] = tbl

        # ğŸ”¹ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ ÙˆØ±Ù‚Ø© "Questions" Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù†ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        qsheet_key = next((k for k in lookup_catalog.keys() if "QUESTION" in k), None)
        if qsheet_key:
            qtbl = lookup_catalog[qsheet_key]
            qtbl.columns = [str(c).strip().upper() for c in qtbl.columns]
            code_col = next((c for c in qtbl.columns if "DIM" in c or "QUESTION" in c or "CODE" in c), None)
            ar_col = next((c for c in qtbl.columns if "ARAB" in c), None)
            if code_col and ar_col:
                code_to_arabic = dict(zip(qtbl[code_col].astype(str).str.upper(),
                                          qtbl[ar_col].astype(str)))
                arabic_row = []
                for c in df.columns:
                    key = c.strip().upper()
                    arabic_row.append(code_to_arabic.get(key, ""))
                arabic_df = pd.DataFrame([arabic_row], columns=df.columns)
                # df = pd.concat([arabic_df, df], ignore_index=True)

    return df, lookup_catalog

def load_all_entities():
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù‡Ø§Øª ÙˆØ¯Ù…Ø¬Ù‡Ø§ ÙÙŠ DataFrame ÙˆØ§Ø­Ø¯ Ù…Ø¹ Ø¹Ù…ÙˆØ¯ ENTITY_NAME"""
    frames = []
    combined_lookup = {}

    for name, conf in ENTITIES.items():
        if conf.get("aggregated"):
            continue

        csv_name = conf["csv"]
        xlsx_name = conf["xlsx"]
        df_i, lookup_i = load_data(csv_name, xlsx_name)

        if df_i is None or df_i.empty:
            continue

        df_i = df_i.copy()
        df_i.insert(0, "ENTITY_NAME", name)

        frames.append(df_i)

        for k, v in lookup_i.items():
            if k not in combined_lookup:
                combined_lookup[k] = v

    if frames:
        df_all = pd.concat(frames, ignore_index=True)
    else:
        df_all = pd.DataFrame()

    return df_all, combined_lookup


def series_to_percent(vals: pd.Series):
    vals = pd.to_numeric(vals, errors="coerce").dropna()
    if len(vals) == 0:
        return np.nan
    mx = vals.max()
    if mx <= 5:
        return ((vals - 1) / 4 * 100).mean()
    elif mx <= 10:
        return ((vals - 1) / 9 * 100).mean()
    else:
        return vals.mean()

def detect_nps(df: pd.DataFrame):
    cand_cols = [c for c in df.columns if ("NPS" in c.upper()) or ("RECOMMEND" in c.upper()) or ("NETPROMOTER" in c.upper())]
    if not cand_cols:
        return np.nan, 0, 0, 0, None
    col = cand_cols[0]
    s = pd.to_numeric(df[col], errors="coerce").dropna()
    if len(s) == 0:
        return np.nan, 0, 0, 0, col
    promoters = (s >= 9).sum()
    passives  = ((s >= 7) & (s <= 8)).sum()
    detract   = (s <= 6).sum()
    total     = len(s)
    promoters_pct = promoters / total * 100
    passives_pct  = passives  / total * 100
    detract_pct   = detract   / total * 100
    nps = promoters_pct - detract_pct
    return nps, promoters_pct, passives_pct, detract_pct, col

def autodetect_metric_cols(df: pd.DataFrame):
    csat_candidates = [c for c in df.columns if "CSAT" in c.upper()]
    csat_col = csat_candidates[0] if csat_candidates else None

    Fees_candidates = [c for c in df.columns if "FEES" in c.upper()]
    Fees_col = Fees_candidates[0] if Fees_candidates else None

    nps_candidates = [c for c in df.columns if "NPS" in c.upper()]
    nps_col = nps_candidates[0] if nps_candidates else None

    return csat_col, Fees_col, nps_col

# ============================
# ØªØ­Ø³ÙŠÙ† Ø´ÙƒÙ„ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
# ============================
st.markdown("""
    <style>
        section[data-testid="stSidebar"] .stSelectbox,
        section[data-testid="stSidebar"] .stTextInput {
            margin-top: -15px !important;
        }
        section[data-testid="stSidebar"] label {
            margin-bottom: -3px !important;
        }
    </style>
""", unsafe_allow_html=True)

# ============================
# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¬Ù‡Ø© Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
# ============================
st.sidebar.markdown(
    """
    <div style='font-size:20px; font-weight:700; margin-bottom:-10px;'>ğŸ¢ Ø§Ø®ØªØ± Ø§Ù„Ø¬Ù‡Ø©</div>
    """,
    unsafe_allow_html=True
)

selected_entity = st.sidebar.selectbox("", list(ENTITIES.keys()))

entity_conf = ENTITIES[selected_entity]
user_conf   = USER_KEYS[selected_entity]

correct_password = user_conf["password"]
is_admin = (user_conf.get("role") == "admin")

# ============================
# Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
# ============================
st.sidebar.markdown(
    """
    <div style='font-size:20px; font-weight:700; margin-bottom:-10px;'>ğŸ” ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±</div>
    """,
    unsafe_allow_html=True
)

password_input = st.sidebar.text_input(
    "",
    type="password",
    help="Ù„Ù† ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¥Ù„Ø§ Ø¨Ø¹Ø¯ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„ØµØ­ÙŠØ­Ø©."
)

if not password_input:
    st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù„Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    st.stop()
elif password_input != correct_password:
    st.error("âŒ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
    st.stop()
else:
    csv_name = entity_conf["csv"]
    xlsx_name = entity_conf["xlsx"]
    df, lookup_catalog = load_data(csv_name, xlsx_name)
    st.sidebar.markdown(f"**Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:** {selected_entity}")

ARABIC_FILTER_TITLES = {
    "AGE": "Ø§Ù„Ø¹Ù…Ø±",
    "SERVICE": "Ø§Ù„Ø®Ø¯Ù…Ø©",
    "LANGUAGE": "Ø§Ù„Ù„ØºØ©",
    "PERIOD": "Ø§Ù„ÙØªØ±Ø©",
    "CHANNEL": "Ø§Ù„Ù‚Ù†Ø§Ø©",
    "ENTITY_NAME": "Ø§Ù„Ø¬Ù‡Ø©"
}

st.sidebar.header("ğŸ›ï¸ Ø§Ù„ÙÙ„Ø§ØªØ±")
df_filtered = df.copy()

common_keys = ["Language", "SERVICE", "AGE", "PERIOD", "CHANNEL", "ENTITY_NAME"]
candidate_filter_cols = [c for c in df.columns if any(k in c.upper() for k in common_keys)]

def apply_lookup(column_name: str, s: pd.Series) -> pd.Series:
    key = column_name.strip().upper()

    match_key = None
    for k in lookup_catalog.keys():
        if k.strip().upper() == key:
            match_key = k
            break

    if match_key is None:
        for k in lookup_catalog.keys():
            if key in k or k in key:
                match_key = k
                break

    if match_key is None:
        return s

    tbl = lookup_catalog[match_key].copy()
    tbl.columns = [str(c).strip().upper() for c in tbl.columns]
    if len(tbl.columns) < 2:
        return s

    code_col = tbl.columns[0]
    name_col = tbl.columns[1]
    map_dict = dict(zip(tbl[code_col].astype(str), tbl[name_col].astype(str)))
    return s.astype(str).map(map_dict).fillna(s)

df_filtered_display = df_filtered.copy()
for col in candidate_filter_cols:
    df_filtered_display[col] = apply_lookup(col, df_filtered[col])

with st.sidebar.expander("ØªØ·Ø¨ÙŠÙ‚/Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙ„Ø§ØªØ±"):
    applied_filters = {}

    for col in candidate_filter_cols:
        df_filtered[col] = apply_lookup(col, df_filtered[col])

        options = df_filtered_display[col].dropna().unique().tolist()
        options_sorted = sorted(options, key=lambda x: str(x))
        default = options_sorted

        label = ARABIC_FILTER_TITLES.get(col.upper(), col)
        sel = st.multiselect(label, options_sorted, default=default)

        applied_filters[col] = sel

for col, selected in applied_filters.items():
    if selected:
        df_filtered = df_filtered[df_filtered[col].isin(selected)]

df_view = df_filtered.copy()

AR_DIST_TITLES = {
    "AGE": "Ø§Ù„Ø¹Ù…Ø±",
    "SERVICE": "Ø§Ù„Ø®Ø¯Ù…Ø©",
    "LANGUAGE": "Ø§Ù„Ù„ØºØ©",
    "PERIOD": "Ø§Ù„ÙØªØ±Ø©",
    "CHANNEL": "Ø§Ù„Ù‚Ù†Ø§Ø©",
}

# =========================================================
# Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
# =========================================================
if is_admin:
    tab_data, tab_sample, tab_kpis, tab_dimensions, tab_pareto, tab_admin = st.tabs([
        "ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        "ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©",
        "ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª",
        "ğŸ§© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯",
        "ğŸ’¬ Ø§Ù„Ù…Ø²Ø¹Ø¬Ø§Øª",
        "ğŸ“Š Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù‡Ø§Øª"
    ])
else:
    tab_data, tab_sample, tab_kpis, tab_dimensions, tab_pareto = st.tabs([
        "ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        "ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©",
        "ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª",
        "ğŸ§© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯",
        "ğŸ’¬ Ø§Ù„Ù…Ø²Ø¹Ø¬Ø§Øª"
    ])

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª + ØªÙ†Ø²ÙŠÙ„
# =========================================================
with tab_data:
    st.dataframe(df_view, use_container_width=True)
    ts = datetime.now().strftime("%Y-%m-%d_%H%M")
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df_view.to_excel(writer, index=False, sheet_name="Filtered_Data")
    st.download_button("ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)", data=buf.getvalue(),
                       file_name=f"Filtered_Data_{ts}.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©
# =========================================================
with tab_sample:
    st.subheader("ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©")
    total = len(df_view)
    st.markdown(
        f"### ğŸ§® Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯: <span style='color:#1E88E5;'>{total:,}</span>",
        unsafe_allow_html=True,
    )

    chart_type = st.radio("ğŸ“Š Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ù…", ["Ù…Ø®Ø·Ø· Ø£Ø¹Ù…Ø¯Ø©", "Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ"], index=0, horizontal=True)

    display_mode = st.radio(
        "ğŸ“‹ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø±Ø¶:",
        ["Ø§Ù„Ø¹Ø¯Ø¯ ÙÙ‚Ø·", "Ø§Ù„Ù†Ø³Ø¨Ø© ÙÙ‚Ø·", "Ø§Ù„Ø¹Ø¯Ø¯ + Ø§Ù„Ù†Ø³Ø¨Ø©"],
        horizontal=True,
        index=1,
    )

    dist_base = ["AGE", "SERVICE", "LANGUAGE", "PERIOD", "CHANNEL"]
    dist_cols = [c for c in candidate_filter_cols if c.upper() in dist_base]

    for col in dist_cols:
        if col not in df_view.columns:
            continue

        counts = df_view[col].value_counts(dropna=True).reset_index()
        counts.columns = [col, "Count"]
        if counts.empty:
            continue

        counts["Percentage"] = counts["Count"] / counts["Count"].sum() * 100

        if display_mode == "Ø§Ù„Ø¹Ø¯Ø¯ ÙÙ‚Ø·":
            y_col = "Count"
            y_label = "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯"
            text_col = counts["Count"].astype(str)
        elif display_mode == "Ø§Ù„Ù†Ø³Ø¨Ø© ÙÙ‚Ø·":
            y_col = "Percentage"
            y_label = "Ø§Ù„Ù†Ø³Ø¨Ø© (%)"
            text_col = counts["Percentage"].map("{:.1f}%".format)
        else:
            y_col = "Count"
            y_label = "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯"
            text_col = counts.apply(lambda x: f"{x['Count']} ({x['Percentage']:.1f}%)", axis=1)

        col_key = col.upper()
        col_label = AR_DIST_TITLES.get(col_key, col)
        title_text = f"ØªÙˆØ²ÙŠØ¹ {col_label}"

        st.markdown(f"### {title_text}")

        if chart_type == "Ù…Ø®Ø·Ø· Ø£Ø¹Ù…Ø¯Ø©":
            fig = px.bar(
                counts,
                x=col,
                y=y_col,
                text=text_col,
                color=col,
                color_discrete_sequence=PASTEL,
                title=title_text,
            )
            fig.update_traces(textposition="outside")
            fig.update_layout(
                title={"text": title_text, "x": 0.5},
                xaxis_title="Ø§Ù„ÙØ¦Ø©",
                yaxis_title=y_label,
                showlegend=False,
                height=500,
            )
            fig.update_layout(title_font_size=20)
            st.plotly_chart(fig, use_container_width=True)
        else:
            fig = px.pie(
                counts,
                names=col,
                values="Count",
                hole=0.3,
                color=col,
                color_discrete_sequence=PASTEL,
                title=title_text,
            )
            fig.update_layout(title={"text": title_text, "x": 0.5}, height=500)
            fig.update_layout(title_font_size=20)

            if display_mode == "Ø§Ù„Ø¹Ø¯Ø¯ ÙÙ‚Ø·":
                fig.update_traces(textposition="inside", texttemplate="%{label}<br>%{value}")
            elif display_mode == "Ø§Ù„Ù†Ø³Ø¨Ø© ÙÙ‚Ø·":
                fig.update_traces(textposition="inside", texttemplate="%{label}<br>%{percent:.1%}")
            else:
                fig.update_traces(textposition="inside", texttemplate="%{label}<br>%{value} (%{percent:.1%})")

            st.plotly_chart(fig, use_container_width=True)

        st.dataframe(
            counts[[col, "Count", "Percentage"]]
            .rename(columns={col: "Ø§Ù„ÙØ¦Ø©", "Count": "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯", "Percentage": "Ø§Ù„Ù†Ø³Ø¨Ø© (%)"})
            .style.format({"Ø§Ù„Ù†Ø³Ø¨Ø© (%)": "{:.1f}%"}),
            use_container_width=True,
            hide_index=True,
        )
        st.markdown("---")

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (CSAT / Fees / NPS)
# =========================================================
with tab_kpis:
    st.subheader("ğŸ“Š Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
    csat_col, Fees_col, nps_col = autodetect_metric_cols(df_view)

    csat = series_to_percent(df_view.get(csat_col, pd.Series(dtype=float))) if csat_col else np.nan
    Fees  = series_to_percent(df_view.get(Fees_col,  pd.Series(dtype=float))) if Fees_col else np.nan
    nps, p_pct, s_pct, d_pct, nps_col = detect_nps(df_view)

    def color_label(score, metric_type):
        if metric_type in ["CSAT", "Fees"]:
            if pd.isna(score):           return "#bdc3c7", "ØºÙŠØ± Ù…ØªØ§Ø­"
            if score < 70:               return "#FF6B6B", "Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§"
            elif score < 80:             return "#FFD93D", "Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†"
            elif score < 90:             return "#6BCB77", "Ø¬ÙŠØ¯"
            else:                        return "#4D96FF", "Ù…Ù…ØªØ§Ø²"
        else:
            if pd.isna(score):           return "#bdc3c7", "ØºÙŠØ± Ù…ØªØ§Ø­"
            if score < 0:                return "#FF6B6B", "Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§"
            elif score < 30:             return "#FFD93D", "Ø¶Ø¹ÙŠÙ"
            elif score < 60:             return "#6BCB77", "Ø¬ÙŠØ¯"
            else:                        return "#4D96FF", "Ù…Ù…ØªØ§Ø²"

    def gauge(score, title, metric_type):
        color, label = color_label(score, metric_type)
        axis_range = [0, 100] if metric_type in ["CSAT", "Fees"] else [-100, 100]
        steps = (
            [{'range': [0, 70], 'color': '#FF6B6B'},
             {'range': [70, 80], 'color': '#FFD93D'},
             {'range': [80, 90], 'color': '#6BCB77'},
             {'range': [90, 100], 'color': '#4D96FF'}]
            if metric_type in ["CSAT", "Fees"]
            else [{'range': [-100, 0], 'color': '#FF6B6B'},
                  {'range': [0, 30], 'color': '#FFD93D'},
                  {'range': [30, 60], 'color': '#6BCB77'},
                  {'range': [60, 100], 'color': '#4D96FF'}]
        )
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=0 if pd.isna(score) else float(score),
            number={'suffix': "Ùª" if metric_type != "NPS" else ""},
            title={'text': title, 'font': {'size': 18}},
            gauge={'axis': {'range': axis_range}, 'bar': {'color': color}, 'steps': steps}
        ))
        fig.update_layout(height=300, margin=dict(l=30, r=30, t=60, b=30))
        return fig, label

    c1, c2, c3 = st.columns(3)
    fig1, lab1 = gauge(csat, "Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø©", "CSAT")
    fig2, lab2 = gauge(Fees,  "Ø§Ù„Ø±Ø¶Ø§ Ø¹Ù† Ø§Ù„Ø±Ø³ÙˆÙ…", "Fees")
    fig3, lab3 = gauge(nps,  "ØµØ§ÙÙŠ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ±ÙˆÙŠØ¬", "NPS")
    c1.plotly_chart(fig1, use_container_width=True)
    c1.markdown(f"**Ø§Ù„ØªÙØ³ÙŠØ±:** {lab1}")
    if csat_col: c1.caption(f"Ø§Ù„Ù…ØµØ¯Ø±: {csat_col}")
    c2.plotly_chart(fig2, use_container_width=True)
    c2.markdown(f"**Ø§Ù„ØªÙØ³ÙŠØ±:** {lab2}")
    if Fees_col: c2.caption(f"Ø§Ù„Ù…ØµØ¯Ø±: {Fees_col}")
    c3.plotly_chart(fig3, use_container_width=True)
    c3.markdown(f"**Ø§Ù„ØªÙØ³ÙŠØ±:** {lab3}")
    if nps_col: c3.caption(f"Ø§Ù„Ù…ØµØ¯Ø±: {nps_col}")
    c3.markdown(f"Ø§Ù„Ù…Ø±ÙˆØ¬ÙˆÙ†: {p_pct:.1f}% | Ø§Ù„Ù…Ø­Ø§ÙŠØ¯ÙˆÙ†: {s_pct:.1f}% | Ø§Ù„Ù…Ø¹Ø§Ø±Ø¶ÙˆÙ†: {d_pct:.1f}%", unsafe_allow_html=True)

    legend_html = """
    <div style='background-color:#f9f9f9;border:1px solid #ddd;border-radius:10px;padding:12px;margin-top:15px;'>
        <h4 style='margin-bottom:8px;'>ğŸ¨ ÙˆØ³ÙŠÙ„Ø© Ø§Ù„Ø¥ÙŠØ¶Ø§Ø­ â€” Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø© / Ø§Ù„Ø±Ø¶Ø§ Ø¹Ù† Ø§Ù„Ø±Ø³ÙˆÙ…</h4>
        ğŸ”´ Ø£Ù‚Ù„ Ù…Ù† 70Ùª â€” Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§<br>
        ğŸŸ¡ Ù…Ù† 70 Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 80Ùª â€” Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†<br>
        ğŸŸ¢ Ù…Ù† 80 Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 90Ùª â€” Ø¬ÙŠØ¯<br>
        ğŸ”µ 90Ùª ÙØ£ÙƒØ«Ø± â€” Ù…Ù…ØªØ§Ø²
    </div>
    <div style='background-color:#f9f9f9;border:1px solid #ddd;border-radius:10px;padding:12px;margin-top:10px;'>
        <h4 style='margin-bottom:8px;'>ğŸ¯ ÙˆØ³ÙŠÙ„Ø© Ø§Ù„Ø¥ÙŠØ¶Ø§Ø­ â€” ØµØ§ÙÙŠ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ±ÙˆÙŠØ¬ (NPS)</h4>
        ğŸ”´ Ø£Ù‚Ù„ Ù…Ù† 0 â€” Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§ (Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§Ø±Ø¶ÙŠÙ† Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ù…Ø±ÙˆØ¬ÙŠÙ†)<br>
        ğŸŸ¡ Ù…Ù† 0 Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 30 â€” Ø¶Ø¹ÙŠÙ (Ø±Ø¶Ø§ Ù…Ø­Ø¯ÙˆØ¯)<br>
        ğŸŸ¢ Ù…Ù† 30 Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 60 â€” Ø¬ÙŠØ¯ (Ø±Ø¶Ø§ Ø¹Ø§Ù…)<br>
        ğŸ”µ 60 ÙØ£ÙƒØ«Ø± â€” Ù…Ù…ØªØ§Ø² (ÙˆÙ„Ø§Ø¡ Ù…Ø±ØªÙØ¹ Ø¬Ø¯Ù‹Ø§)
    </div>
    """
    st.markdown(legend_html, unsafe_allow_html=True)

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (3 Ø£Ø¨Ø¹Ø§Ø¯ ÙÙ‚Ø·)
# =========================================================
with tab_dimensions:
    dim_subcols = [c for c in df_view.columns if re.match(r"Dim\d+\.", str(c).strip())]
    if not dim_subcols:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙØ±Ø¹ÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ù…Ø«Ù„ Dim1.1 Ø£Ùˆ Dim2.3).")
    else:
        main_dim_map = {}
        for i in range(1, 6):
            sub = [c for c in df_view.columns if str(c).startswith(f"Dim{i}.")]
            if sub:
                main_dim_map[f"Dim{i}"] = df_view[sub].apply(pd.to_numeric, errors="coerce").mean(axis=1)

        summary = []
        for dim, series in main_dim_map.items():
            score = series_to_percent(series)
            summary.append({"Dimension": dim, "Score": score})

        dims = pd.DataFrame(summary).dropna()
        if dims.empty:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ÙƒØ§ÙÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯.")
        else:
            dims["Order"] = dims["Dimension"].str.extract(r"(\d+)").astype(float)
            dims = dims.sort_values("Order").reset_index(drop=True)

            for sheet_name in lookup_catalog.keys():
                if "QUESTION" in sheet_name:
                    qtbl = lookup_catalog[sheet_name].copy()
                    qtbl.columns = [str(c).strip().upper() for c in qtbl.columns]

                    code_col = next((c for c in qtbl.columns if any(k in c for k in ["DIM", "CODE", "QUESTION", "ID"])), None)
                    name_col = next((c for c in qtbl.columns if any(k in c for k in ["ARABIC", "NAME", "LABEL", "TEXT"])), None)

                    if code_col and name_col:
                        def _norm(s):
                            return s.astype(str).str.upper().str.replace(r"\\s+", "", regex=True)

                        code_series = _norm(qtbl[code_col])
                        name_series = qtbl[name_col].astype(str)
                        map_dict = dict(zip(code_series, name_series))

                        dims["Dimension"] = (
                            _norm(dims["Dimension"])
                            .map(map_dict)
                            .fillna(dims["Dimension"])
                        )
                    break

            def cat(score):
                if score < 70:  return "ğŸ”´ Ø¶Ø¹ÙŠÙ"
                elif score < 80: return "ğŸŸ¡ Ù…ØªÙˆØ³Ø·"
                elif score < 90: return "ğŸŸ¢ Ø¬ÙŠØ¯"
                else:            return "ğŸ”µ Ù…Ù…ØªØ§Ø²"
            dims["Category"] = dims["Score"].apply(cat)

            fig = px.bar(
                dims, x="Dimension", y="Score", text="Score", color="Category",
                color_discrete_map={
                    "ğŸ”´ Ø¶Ø¹ÙŠÙ": "#FF6B6B",
                    "ğŸŸ¡ Ù…ØªÙˆØ³Ø·": "#FFD93D",
                    "ğŸŸ¢ Ø¬ÙŠØ¯":   "#6BCB77",
                    "ğŸ”µ Ù…Ù…ØªØ§Ø²": "#4D96FF"
                },
                title="<span style='font-size:28px; font-weight:bold;'>ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯</span>"
            )
            fig.update_traces(texttemplate="%{text:.1f}%", textposition="outside")
            fig.update_layout(
                title={'text': "<span style='font-size:22px; font-weight:bold;'>ØªØ­Ù„ÙŠÙ„ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ğŸ“Š</span>", 'x': 0.5, 'xanchor': 'center'},
                yaxis=dict(range=[0, 100]),
                xaxis_title="Ø§Ù„Ø¨Ø¹Ø¯",
                yaxis_title="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© (%)"
            )

            st.plotly_chart(fig, use_container_width=True)
            st.markdown(
                """
                **ğŸ—‚ï¸ ÙˆØ³ÙŠÙ„Ø© Ø§Ù„Ø¥ÙŠØ¶Ø§Ø­:**
                - ğŸ”´ Ø£Ù‚Ù„ Ù…Ù† 70Ùª â€” Ø¶Ø¹ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø¡  
                - ğŸŸ¡ Ù…Ù† 70Ùª Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 80Ùª â€” Ù…ØªÙˆØ³Ø·  
                - ğŸŸ¢ Ù…Ù† 80Ùª Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 90Ùª â€” Ø¬ÙŠØ¯  
                - ğŸ”µ 90Ùª ÙØ£ÙƒØ«Ø± â€” Ù…Ù…ØªØ§Ø²  
                """,
                unsafe_allow_html=True
            )
            st.dataframe(
                dims[["Dimension", "Score"]]
                .rename(columns={"Dimension": "Ø§Ù„Ø¨Ø¹Ø¯", "Score": "Ø§Ù„Ù†Ø³Ø¨Ø© (%)"})
                .style.format({"Ø§Ù„Ù†Ø³Ø¨Ø© (%)": "{:.1f}%"}),
                use_container_width=True,
                hide_index=True
            )

# =========================================================
# ğŸ’¬ ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø±Ø¶Ø§ (Most_Unsat) Ø¨Ø·Ø±ÙŠÙ‚Ø© Pareto
# =========================================================
with tab_pareto:
    st.subheader("ğŸ’¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø²Ø¹Ø¬Ø§Øª")

    unsat_col = next((c for c in df_view.columns if "MOST_UNSAT" in c.upper()), None)
    if not unsat_col:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…ÙˆØ¯ Most_Unsat ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
    else:
        data_unsat = df_view[[unsat_col]].copy()
        data_unsat.columns = ["Comment"]
        data_unsat["Comment"] = data_unsat["Comment"].astype(str).str.strip()

        exclude_terms = ["", " ", "Ù„Ø§ ÙŠÙˆØ¬Ø¯", "Ù„Ø§ÙŠÙˆØ¬Ø¯", "Ù„Ø§Ø´ÙŠØ¡", "Ù„Ø§ Ø´ÙŠØ¡",
                         "none", "no", "nothing", "nil", "Ø¬ÙŠØ¯", "Ù…Ù…ØªØ§Ø²", "ok", "ØªÙ…Ø§Ù…", "great"]
        data_unsat = data_unsat[~data_unsat["Comment"].str.lower().isin([t.lower() for t in exclude_terms])]
        data_unsat = data_unsat[data_unsat["Comment"].apply(lambda x: len(x.split()) >= 2)]

        if data_unsat.empty:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù†ØµÙŠØ© ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ.")
        else:
            themes = {
                "Ø§Ù„Ø³Ø±Ø¹Ø© / Ø²Ù…Ù† Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²": [
                    "Ø¨Ø·Ø¡", "Ø§Ù„Ø¨Ø·Ø¡", "Ø¨Ø·ÙŠØ¡", "Ø§Ø­ÙŠØ§Ù†Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø¨Ø·Ø¦Ø§Ù‹", "Site loading", "loading", "Delay", "Late", "Long delay",
                    "Ø§Ù„ØªØ£Ø®ÙŠØ± Ø§Ù„ÙƒØ«ÙŠØ±", "ØªØ§Ø®ÙŠØ± Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ù‡", "ØªØ§Ø®ÙŠØ± Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª", "Ø·ÙˆÙ„ ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©", "Ø·ÙˆÙ„ ÙØªØ±Ø© Ø§Ù„Ø§Ù†Ø¬Ø§Ø²", "Ø§Ù„ØªØ§Ø®ÙŠØ±", "ØªØ§Ø®ÙŠØ±", "Ø§Ù„ØªØ£Ø®ÙŠØ±"
                ],
                "Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª / Ø§Ù„Ø®Ø·ÙˆØ§Øª": [
                    "Ø¥Ø¬Ø±Ø§Ø¡", "Ø§Ø¬Ø±Ø§Ø¡", "Ø¹Ù…Ù„ÙŠØ©", "process","Ø®Ø·ÙˆØ§Øª", "Ù…Ø±Ø§Ø­Ù„", "Ù†Ù…ÙˆØ°Ø¬","ÙƒØ«Ø±Ø© Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª", "ÙƒØ«Ø±Ø© Ø§Ù„ØªØ¹Ù‚ÙŠØ¯Ø§Øª","ØµØ¹ÙˆØ¨Ø© Ø§Ù„Ø§Ø¬Ø±Ø§Ø¡Ø§Øª",
                    "ÙƒØ«Ø±Ø© ØªØºÙŠÙŠØ± Ø§Ù„Ø§Ø¬Ø±Ø§Ø¡Ø§Øª", "ÙƒØ«Ø±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", "Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø®Ø·ÙˆØ§Øª ÙˆØ§Ø¶Ø­Ø©", "ÙƒØ«Ø±Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„", "Ø§Ù„Ø§Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©",
                    "ØµØ¹ÙˆØ¨Ø© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…"
                ],
                "Ø§Ù„Ø±Ø³ÙˆÙ… / Ø§Ù„Ø¯ÙØ¹ Ø§Ù„Ø±Ù‚Ù…ÙŠ": [
                    "Ø±Ø³ÙˆÙ…", "Ø¯ÙØ¹ Ø§Ù„Ø±Ø³ÙˆÙ…", "Ø¯ÙØ¹ Ø±Ø³ÙˆÙ… Ø¨Ø¯ÙˆÙ† Ù†ØªÙŠØ¬Ø©", "Ø®ØµÙ… Ø§Ù„Ù…Ø¨Ù„Øº", "Ø§Ø®Ø³Ø± ÙÙ„ÙˆØ³", "Ø§Ù„Ù…Ø¨Ø§Ù„Øº Ø§Ù„Ù…Ø§Ù„ÙŠØ©", "Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ", "Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø¹Ø§Ù„ÙŠØ©",
                    "ÙŠØ±Ø¬Ù‰ ØªØ³Ù‡ÙŠÙ„ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¯ÙØ¹", "Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¯ÙØ¹ Ø¨Ø·ÙŠØ¦Ø© Ø¬Ø¯Ø§", "Ø¹Ø¯Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¨Ù„Øº", "Ø±Ø³ÙˆÙ… Ø§Ù„Ø¯ÙØ¹ Ø§Ù„Ø§Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¨ÙˆØ§Ø¨Ø©",
                    "payment issues occurred most of the time"
                ],
                "Ø§Ù„ØªÙˆØ§ØµÙ„ / Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ": [
                    "ØªÙˆØ§ØµÙ„", "Ø§ØªØµØ§Ù„", "Ø±Ø¯", "response", "support", "customer support", "customer service", "ØµØ¹ÙˆØ¨Ø© Ø§Ù„ØªÙˆØ§ØµÙ„",
                    "ØµØ¹ÙˆØ¨Ø© Ø§Ù„ØªÙˆØ§ØµÙ„ ÙÙŠ Ø­Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ù…Ø´ÙƒÙ„Ø©", "Ø¹Ø¯Ù… Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙØ±ÙŠÙ‚ Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ", "Ø¹Ø¯Ù… Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ù„Ø­Ù„ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…",
                    "Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ Ù„ÙŠØ³Øª Ø³Ù„Ø³Ù‡", "Ø¹Ø¯Ù… Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©", "Ø¹Ø¯Ù… Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ù‡ Ø§Ù„Ø³Ø±ÙŠØ¹Ù‡", "Ù„Ù… Ø£ØªÙ„Ù‚Ù‰ Ø£ÙŠ Ø±Ø¯",
                    "Ù„Ù… Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ø´ÙƒÙˆÙ‰", "NO PROPER CUSTOMER SUPPORT", "NEED TO EASLY CONTACT TO CUSTOMER SUPPORT ONLINE"
                ],
                "Ø§Ù„ÙˆØ¶ÙˆØ­ / Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª": [
                    "There is not proper information in English", "Ù…Ø¹Ù„ÙˆÙ…Ø©", "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", "ØªÙØ§ØµÙŠÙ„", "Ø¨ÙŠØ§Ù†Ø§Øª", "ØºÙŠØ± ÙˆØ§Ø¶Ø­Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ù‡",
                    "ØµØ¹ÙˆØ¨Ø© Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", "Ù‚Ù„Ø© ÙˆØ¶ÙˆØ­ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª", "Ø¹Ø¯Ù… ÙˆØ¶ÙˆØ­ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª", "Ø¹Ø¯Ù… ÙˆØ¶ÙˆØ­ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø±ÙØ¶",
                    "Properly information not giving", "court communication in Arabic only"
                ],
                "Ø§Ù„Ø£Ù…Ø§Ù† / Ø§Ù„Ø¯Ø®ÙˆÙ„": [
                    "Ø¯Ø®ÙˆÙ„", "login", "ØªØ­Ù‚Ù‚", "ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±", "Ø£Ù…Ø§Ù†", "Ø¹Ø¯Ù… Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¹Ø¨Ø± Ø§Ù„Ù‡Ø§ØªÙ",
                    "Some issues when accessing with UAE pass", "Some bug with app access", "Ø¹Ø¯Ù… Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø·Ù„Ø¨"
                ],
                "Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¹Ø§Ù…Ø©": [
                    "Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…", "Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ©", "Ø¹Ø¯Ù… ÙØªØ­ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„Ù…ÙˆÙ‚Ø¹", "Ø§Ù„Ù…ØªØµÙØ­ Ø¨Ø·Ø¦ Ø¬Ø¯Ø§", "Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ«",
                    "ØªÙˆÙ‚Ù Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø¹Ù† Ø§Ù„Ø¹Ù…Ù„", "Errors for the service", "Bug", "Some bug with app access","Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ¹Ø¯ÙŠÙ„Ø§Øª"
                ],
                "Ø±ÙØ¹ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª": [
                    "Ø·Ø±ÙŠÙ‚Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª", "ØµØ¹ÙˆØ¨Ø© Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª", "Ø§Ù„Ù…ØªØµÙØ­ Ù„Ø§ ÙŠØ­ÙØ¸ Ù…Ø³ØªÙ†Ø¯Ø§Øª", "the repeat upload of papers",
                    "No option for attaching the photo", "ØªÙ… Ø§Ø±ÙØ§Ù‚ Ø§Ù„Ø§ÙˆØ±Ø§Ù‚ ÙˆÙ„Ù… ØªØ¸Ù‡Ø±", "Ø¹Ø¯Ù… Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ ØªØ®Ù„ÙŠØµ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø© Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª",
                    "ØµØ¹ÙˆØ¨Ø© ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø¹Ø¨Ø± Ø§Ù„Ù…ÙˆÙ‚Ø¹/Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
                ],
            }

            def classify_text(txt):
                t = txt.lower()
                for theme, keywords in themes.items():
                    if any(k.lower() in t for k in keywords):
                        return theme
                return "ØºÙŠØ± Ù…ØµÙ†Ù‘Ù"

            data_unsat["Ø§Ù„Ù…Ø­ÙˆØ±"] = data_unsat["Comment"].apply(classify_text)
            data_unsat = data_unsat[data_unsat["Ø§Ù„Ù…Ø­ÙˆØ±"] != "ØºÙŠØ± Ù…ØµÙ†Ù‘Ù"]

            summary = data_unsat.groupby("Ø§Ù„Ù…Ø­ÙˆØ±").agg({"Comment": lambda x: " / ".join(x.tolist())}).reset_index()

            summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"] = summary["Comment"].apply(lambda x: len(x.split("/")))
            summary = summary.sort_values("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª", ascending=False).reset_index(drop=True)
            summary["Ø§Ù„Ù†Ø³Ø¨Ø© (%)"] = summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"] / summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"].sum() * 100
            summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] = summary["Ø§Ù„Ù†Ø³Ø¨Ø© (%)"].cumsum()
            summary["Ø§Ù„Ù„ÙˆÙ†"] = np.where(summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] <= 80, "#E74C3C", "#BDC3C7")

            if not summary[summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] > 80].empty:
                first_above = summary[summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] > 80].index[0]
                summary.loc[first_above, "Ø§Ù„Ù„ÙˆÙ†"] = "#E74C3C"

            st.dataframe(
                summary[["Ø§Ù„Ù…Ø­ÙˆØ±", "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª", "Ø§Ù„Ù†Ø³Ø¨Ø© (%)", "Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)", "Comment"]]
                .rename(columns={"Comment": "Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª (Ù…Ø¬Ù…Ø¹Ø©)"}).style.format({
                    "Ø§Ù„Ù†Ø³Ø¨Ø© (%)": "{:.1f}%",
                    "Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)": "{:.1f}%"
                }),
                use_container_width=True,
                hide_index=True
            )

            fig = go.Figure()
            fig.add_bar(x=summary["Ø§Ù„Ù…Ø­ÙˆØ±"], y=summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"], marker_color=summary["Ø§Ù„Ù„ÙˆÙ†"], name="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª")
            fig.add_scatter(
                x=summary["Ø§Ù„Ù…Ø­ÙˆØ±"],
                y=summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"],
                yaxis="y2",
                mode="lines+markers+text",
                name="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)",
                text=[f"{v:.1f}%" for v in summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"]],
                textposition="top center",
                line=dict(color="#2E86DE", width=3)
            )
            fig.update_layout(
                title={"text": "ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø±ÙŠØªÙˆ - Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©", "x": 0.5, "y": 0.95, "xanchor": "center", "yanchor": "top"},
                title_font_size=20,
                xaxis=dict(title="Ø§Ù„Ù…Ø­ÙˆØ±", tickangle=-15),
                yaxis=dict(title="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"),
                yaxis2=dict(title="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)", overlaying="y", side="right", range=[0, 110]),
                height=600,
                bargap=0.3,
                legend=dict(orientation="h", y=-0.2)
            )
            st.plotly_chart(fig, use_container_width=True)

            pareto_buffer = io.BytesIO()
            with pd.ExcelWriter(pareto_buffer, engine="openpyxl") as writer:
                summary.to_excel(writer, index=False, sheet_name="Pareto_Results")

            pareto_buffer.seek(0)

            st.download_button(
                label="ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Pareto (Excel)",
                data=pareto_buffer.getvalue(),
                file_name=f"Pareto_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø®Ø§Øµ Ù„Ø­ÙƒÙˆÙ…Ø© Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©: Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ù‡Ø§Øª ÙÙŠ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø£Ø¨Ø¹Ø§Ø¯
# =========================================================
if is_admin:
    df_all, _ = load_all_entities()

    with tab_admin:

        if "ENTITY_NAME" not in df_all.columns:
            st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ ENTITY_NAME ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ù‘Ø¹Ø©.")
        else:
            # =========================================================
            # 1) Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù‡Ø© + ØªÙ†Ø²ÙŠÙ„
            # =========================================================
            csat_col, Fees_col, nps_col = autodetect_metric_cols(df_all)

            rows = []
            for ent, g in df_all.groupby("ENTITY_NAME"):
                row = {"Ø§Ù„Ø¬Ù‡Ø©": ent, "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯": len(g)}

                if csat_col:
                    row["Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (%)"] = series_to_percent(g[csat_col])
                if Fees_col:
                    row["Ø§Ù„Ø±Ø¶Ø§ Ø¹Ù† Ø§Ù„Ø±Ø³ÙˆÙ… (%)"] = series_to_percent(g[Fees_col])

                nps_val, _, _, _, _ = detect_nps(g)
                row["NPS (%)"] = nps_val

                rows.append(row)

            kpi_df = pd.DataFrame(rows)

            if kpi_df.empty:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.")
            else:
                st.markdown(
                    """
                    <h3 style='text-align:center; font-size:22px; font-weight:bold;'>
                    ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù‡Ø©
                    </h3>
                    """,
                    unsafe_allow_html=True
                )

                kpi_display = kpi_df.copy()
                for c in ["Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (%)", "Ø§Ù„Ø±Ø¶Ø§ Ø¹Ù† Ø§Ù„Ø±Ø³ÙˆÙ… (%)", "NPS (%)"]:
                    if c in kpi_display.columns:
                        kpi_display[c] = pd.to_numeric(kpi_display[c], errors="coerce").round(1)

                st.dataframe(
                    kpi_display.style.format({
                        "Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (%)": "{:.1f}%",
                        "Ø§Ù„Ø±Ø¶Ø§ Ø¹Ù† Ø§Ù„Ø±Ø³ÙˆÙ… (%)": "{:.1f}%",
                        "NPS (%)": "{:.1f}%",
                        "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯": "{:,.0f}"
                    }),
                    use_container_width=True,
                    hide_index=True
                )

                # âœ… ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
                kpi_buf = io.BytesIO()
                with pd.ExcelWriter(kpi_buf, engine="openpyxl") as writer:
                    kpi_display.to_excel(writer, index=False, sheet_name="KPI_Comparison")
                st.download_button(
                    "ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (Excel)",
                    data=kpi_buf.getvalue(),
                    file_name=f"KPI_Comparison_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

            st.markdown("---")

            # =========================================================
            # 2) Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ù…Ø±ØªØ¨): Ø§Ù„Ø¬Ù‡Ø§Øª ØµÙÙˆÙ Ã— Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø£Ø¹Ù…Ø¯Ø© + ØªÙ†Ø²ÙŠÙ„
            # =========================================================
            dim_subcols = [c for c in df_all.columns if re.match(r"Dim\d+\.", str(c).strip())]

            if not dim_subcols:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙØ±Ø¹ÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ù…Ø«Ù„ Dim1.1 Ø£Ùˆ Dim2.3) ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
            else:
                main_ids = sorted({
                    int(re.match(r"Dim(\d+)\.", str(c).strip()).group(1))
                    for c in dim_subcols
                    if re.match(r"Dim(\d+)\.", str(c).strip())
                })

                # Ø­Ø³Ø§Ø¨ Ù†ØªÙŠØ¬Ø© ÙƒÙ„ Ø¨ÙØ¹Ø¯ Ø±Ø¦ÙŠØ³ÙŠ Ù„ÙƒÙ„ Ø¬Ù‡Ø©
                rows = []
                for ent, g in df_all.groupby("ENTITY_NAME"):
                    for i in main_ids:
                        sub = [c for c in g.columns if str(c).startswith(f"Dim{i}.")]
                        if not sub:
                            continue

                        dim_series = g[sub].apply(pd.to_numeric, errors="coerce").mean(axis=1)
                        score = series_to_percent(dim_series)

                        rows.append({
                            "Ø§Ù„Ø¬Ù‡Ø©": ent,
                            "Dimension": f"Dim{i}",
                            "Score": score
                        })

                dim_comp_df = pd.DataFrame(rows).dropna(subset=["Score"])

                if dim_comp_df.empty:
                    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„ÙƒÙ„ Ø¬Ù‡Ø©.")
                else:
                    # ØªØ³Ù…ÙŠØ© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ø³Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ù…Ù† Questions Ø¥Ù† ØªÙˆÙØ±Øª)
                    dim_comp_df["Dimension_label"] = dim_comp_df["Dimension"]

                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù† ÙˆØ±Ù‚Ø© Questions Ø¥Ù† ÙˆÙØ¬Ø¯Øª
                    for sheet_name in lookup_catalog.keys():
                        if "QUESTION" in sheet_name.upper():
                            qtbl = lookup_catalog[sheet_name].copy()
                            qtbl.columns = [str(c).strip().upper() for c in qtbl.columns]

                            code_col = next((c for c in qtbl.columns if any(k in c for k in ["DIM", "CODE", "QUESTION", "ID"])), None)
                            name_col = next((c for c in qtbl.columns if any(k in c for k in ["ARABIC", "NAME", "LABEL", "TEXT"])), None)

                            if code_col and name_col:
                                def _norm(s):
                                    return s.astype(str).str.upper().str.replace(r"\s+", "", regex=True)

                                map_dict = dict(zip(_norm(qtbl[code_col]), qtbl[name_col].astype(str)))
                                dim_comp_df["Dimension_label"] = (
                                    _norm(dim_comp_df["Dimension"]).map(map_dict).fillna(dim_comp_df["Dimension"])
                                )
                            break

                    dim_comp_df["Score"] = pd.to_numeric(dim_comp_df["Score"], errors="coerce").round(1)

                    st.markdown(
                        """
                        <h3 style='text-align:center; font-size:22px; font-weight:bold;'>
                        ğŸ“‹ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù‡Ø§Øª
                        </h3>
                        """,
                        unsafe_allow_html=True
                    )

                    # âœ… Pivot: Ø§Ù„Ø¬Ù‡Ø§Øª ØµÙÙˆÙ Ã— Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø£Ø¹Ù…Ø¯Ø©
                    dim_pivot = (
                        dim_comp_df
                        .pivot_table(
                            index="Ø§Ù„Ø¬Ù‡Ø©",
                            columns="Dimension_label",
                            values="Score",
                            aggfunc="mean"
                        )
                        .reset_index()
                    )

                    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: (Ø§Ù„Ø¬Ù‡Ø© Ø£ÙˆÙ„Ø§Ù‹) Ø«Ù… Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø­Ø³Ø¨ ØªØ±ØªÙŠØ¨ Dim1, Dim2, ...
                    label_order = (
                        dim_comp_df[["Dimension", "Dimension_label"]]
                        .drop_duplicates()
                        .assign(Order=lambda d: d["Dimension"].str.extract(r"(\d+)").astype(float))
                        .sort_values("Order")["Dimension_label"]
                        .tolist()
                    )
                    ordered_cols = ["Ø§Ù„Ø¬Ù‡Ø©"] + [c for c in label_order if c in dim_pivot.columns]
                    dim_pivot = dim_pivot[ordered_cols]

                    st.dataframe(
                        dim_pivot.style.format({c: "{:.1f}%" for c in dim_pivot.columns if c != "Ø§Ù„Ø¬Ù‡Ø©"}),
                        use_container_width=True,
                        hide_index=True
                    )

                    # âœ… ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Pivot)
                    dim_buf = io.BytesIO()
                    with pd.ExcelWriter(dim_buf, engine="openpyxl") as writer:
                        dim_pivot.to_excel(writer, index=False, sheet_name="Dimensions_Comparison")
                    st.download_button(
                        "ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Excel)",
                        data=dim_buf.getvalue(),
                        file_name=f"Dimensions_Comparison_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
             
# =========================================================
# ØªØ­Ø³ÙŠÙ†Ø§Øª Ø´ÙƒÙ„ÙŠØ©
# =========================================================
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer, [data-testid="stFooter"] {opacity: 0.03 !important; height: 1px !important; overflow: hidden !important;}
    </style>
""", unsafe_allow_html=True)
#Ù†Ø¶ÙŠÙ Ø§Ù„Ø¹Ø§Ù… Ø§Ù„Ù…Ù‚Ø¨Ù„ Ù†Ù‚Ø·ØªÙŠÙ† Ù…Ù† Ø´Ø§Øª Ø¬ÙŠ Ø¨ÙŠ ØªÙŠØŒ Ù†Ù‚Ø·ØªÙŠ Ø§Ù„ØªÙˆØµÙŠØ§Øª ÙˆØ¥Ø¹Ø¯Ø§Ø¯ ØªÙ‚Ø±ÙŠØ± ÙƒØ§Ù…Ù„. Ù…Ù…ÙƒÙ† Ø£Ù† Ù†Ø¹Ø·ÙŠ Ù†Ù…ÙˆØ°Ø¬ ØªÙ‚Ø±ÙŠØ± ÙˆÙ†Ø·Ù„Ø¨ Ù…Ù†Ù‡ Ø£Ù† ÙŠÙ‚ÙˆÙ… Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ ØªÙ‚Ø±ÙŠØ± Ù†ÙØ³Ù‡. 



