
# -*- coding: utf-8 -*-
# Arabic CX Dashboard (3 Dimensions) â€” Streamlit
# Files expected in the same folder:
#   - MN.csv                          â† raw survey data
#   - Digital_Data_tables.xlsx         â† lookup/metadata tables
#
# Run:
#   streamlit run Arabic_Dashboard.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io, re
from datetime import datetime
from pathlib import Path
USER_KEYS = {
    "Ø¨Ù„Ø¯ÙŠØ© Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "password": st.secrets["users"]["MN"],
        "role": "center",
        "file": "MN.csv"
    },
    "Ù…Ø­Ø§ÙƒÙ… Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "password": st.secrets["users"]["CR"],
        "role": "center",
        "file": "CR.csv"
    },
    "Ø§Ù„Ù†ÙŠØ§Ø¨Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "password": st.secrets["users"]["PR"],
        "role": "center",
        "file": "PR.csv"
    },
    "Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©": {
        "password": st.secrets["users"]["EC"],
        "role": "center",
        "file": "EC.csv"
    },
    "Ø¬Ù…Ø§Ø±Ùƒ Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "password": st.secrets["users"]["CU"],
        "role": "center",
        "file": "CU.csv"
    },
    "Ù‡ÙŠØ¦Ø© Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„ØªÙ†Ù…ÙŠØ©": {
        "password": st.secrets["users"]["EN"],
        "role": "center",
        "file": "EN.csv"
    },
    "Ø§Ù„Ø£Ù…Ø§Ù†Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ": {
        "password": st.secrets["users"]["GS"],
        "role": "admin",
        "file": "Centers_Master.csv"   # ØºÙŠÙ‘Ø± Ø§Ù„Ø§Ø³Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ Ù…Ù„Ù Ù…Ø®ØªÙ„Ù Ù„Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
    }
}
# =========================================================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© + Ø§ØªØ¬Ø§Ù‡ RTL
# =========================================================
st.set_page_config(page_title="ØªÙ‚Ø±ÙŠØ± ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…ØªØ¹Ø§Ù…Ù„ ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© 2025", layout="wide")
PASTEL = px.colors.qualitative.Pastel

# Ø´Ø¹Ø§Ø± Ø£Ø¹Ù„Ù‰ Ø§Ù„ØµÙØ­Ø© (Ø§Ø³ØªØ¨Ø¯Ù„ Ø¨Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ø¥Ø°Ø§ Ø±ØºØ¨Øª)
LOGO_URL = "https://raw.githubusercontent.com/gsecrak/rakdcx2025/main/assets/mini_header3.png"
st.markdown(f"""
    <div style="text-align:center; margin-top:-40px;">
        <img src="{LOGO_URL}" alt="Logo" style="width:950px; max-width:95%; height:auto;">
    </div>
    <hr style="margin-top:20px; margin-bottom:10px;">
""", unsafe_allow_html=True)

# Ø§ØªØ¬Ø§Ù‡ Ø¹Ø±Ø¨ÙŠ ÙˆØ®Ø· Ù…Ù†Ø§Ø³Ø¨
st.markdown("""
    <style>
        html, body, [class*="css"] {
            direction: rtl;
            text-align: right;
            font-family: "Tajawal","Cairo","Segoe UI";
        }

        /* Ø´Ø±ÙŠØ· Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª: Ø§ØªØ¬Ø§Ù‡ Ø¹Ø±Ø¨ÙŠ ÙˆØ«Ø§Ø¨Øª ÙÙŠ Ø§Ù„ÙŠÙ…ÙŠÙ† */
        .stTabs [data-baseweb="tab-list"] {
            direction: rtl !important;          /* Ø£ÙˆÙ„ ØªØ¨ÙˆÙŠØ¨ ÙŠÙƒÙˆÙ† Ø¹Ù†Ø¯ Ø§Ù„ÙŠÙ…ÙŠÙ† */
            display: flex !important;
            justify-content: flex-start !important;  /* ÙŠØ¨Ø¯Ø£ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† */
            width: 100% !important;             /* ÙŠØ£Ø®Ø° Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø·Ø± Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ */
        }

        /* Ù†Øµ ÙƒÙ„ ØªØ¨ÙˆÙŠØ¨ ÙŠÙƒÙˆÙ† RTL ÙˆÙ…Ø­Ø§Ø°Ù‰ ÙŠÙ…ÙŠÙ† */
        .stTabs [data-baseweb="tab"] > div {
            direction: rtl !important;
            text-align: right !important;
        }

        .stDownloadButton, .stButton > button {
            font-weight: 600;
        }
    </style>
""", unsafe_allow_html=True)


# Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø¬Ù‡Ø§Øª ÙˆØ§Ù„Ù…Ù„ÙØ§Øª
ENTITIES = {
    "Ø¨Ù„Ø¯ÙŠØ© Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "csv": "MN.csv",
        "xlsx": "Data_tables_MN.xlsx",
    },
    "Ù…Ø­Ø§ÙƒÙ… Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "csv": "CR.csv",
        "xlsx": "Data_tables_CR.xlsx",
    },
    "Ø§Ù„Ù†ÙŠØ§Ø¨Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙÙŠ Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "csv": "PR.csv",
        "xlsx": "Data_tables_PR.xlsx",
    },
    "Ø¯Ø§Ø¦Ø±Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠØ©": {
        "csv": "EC.csv",
        "xlsx": "Data_tables_EC.xlsx",
    },
    "Ø¬Ù…Ø§Ø±Ùƒ Ø±Ø£Ø³ Ø§Ù„Ø®ÙŠÙ…Ø©": {
        "csv": "CU.csv",
        "xlsx": "Data_tables_CU.xlsx",
    },
    "Ù‡ÙŠØ¦Ø© Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„ØªÙ†Ù…ÙŠØ©": {
        "csv": "EN.csv",
        "xlsx": "Data_tables_EN.xlsx",
    },
     # ğŸ‘‡ Ø¬Ù‡Ø© Ø§Ù„Ø£Ø¯Ù…Ù† (ØªØ¬Ù…ÙŠØ¹ ÙƒÙ„ Ø§Ù„Ø¬Ù‡Ø§Øª)
    "Ø§Ù„Ø£Ù…Ø§Ù†Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ": {
        "csv": "Centers_Master.csv",         # Ù„Ù† Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§
        "xlsx": "Data_tables_MASTER.xlsx",        # Ù„Ù† Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§
        #"aggregated": True,  # Ø¹Ù„Ø§Ù…Ø© Ø£Ù†Ù‡Ø§ Ø¬Ù‡Ø© ØªØ¬Ù…ÙŠØ¹
    },
}

# =========================================================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# =========================================================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© Ø³Ø·Ø± Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ (Arabic Labels)
# =========================================================
#@st.cache_data(show_spinner=False)
def load_data(csv_name: str, xlsx_name: str):
    # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    df = pd.read_csv(csv_name, encoding="utf-8", low_memory=False)
    df.columns = [c.strip().upper() for c in df.columns]
    df.columns = [c.replace('DIM', 'Dim') for c in df.columns]

    # Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙˆØµÙÙŠØ©
    lookup_catalog = {}
    xls_path = Path(xlsx_name)
    if xls_path.exists():
        xls = pd.ExcelFile(xls_path)
        for sheet in xls.sheet_names:
            tbl = pd.read_excel(xls, sheet_name=sheet)
            tbl.columns = [str(c).strip().upper() for c in tbl.columns]
            lookup_catalog[sheet.strip().upper()] = tbl

        # ğŸ”¹ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ ÙˆØ±Ù‚Ø© "Questions" Ù„Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù†ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        qsheet_key = next((k for k in lookup_catalog.keys() if "QUESTION" in k), None)
        if qsheet_key:
            qtbl = lookup_catalog[qsheet_key]
            qtbl.columns = [str(c).strip().upper() for c in qtbl.columns]
            code_col = next((c for c in qtbl.columns if "DIM" in c or "QUESTION" in c or "CODE" in c), None)
            ar_col = next((c for c in qtbl.columns if "ARAB" in c), None)
            if code_col and ar_col:
                code_to_arabic = dict(zip(qtbl[code_col].astype(str).str.upper(),
                                          qtbl[ar_col].astype(str)))
                # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø·Ø± Ù…Ø¹Ø§Ù†ÙŠ Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ df
                arabic_row = []
                for c in df.columns:
                    key = c.strip().upper()
                    arabic_row.append(code_to_arabic.get(key, ""))
                # Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
                arabic_df = pd.DataFrame([arabic_row], columns=df.columns)
                # df = pd.concat([arabic_df, df], ignore_index=True)

    return df, lookup_catalog
def load_all_entities():
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù‡Ø§Øª ÙˆØ¯Ù…Ø¬Ù‡Ø§ ÙÙŠ DataFrame ÙˆØ§Ø­Ø¯ Ù…Ø¹ Ø¹Ù…ÙˆØ¯ ENTITY_NAME"""
    frames = []
    combined_lookup = {}

    for name, conf in ENTITIES.items():
        # Ù†ØªØ®Ø·Ù‰ Ø¬Ù‡Ø© Ø§Ù„Ø£Ø¯Ù…Ù† Ù†ÙØ³Ù‡Ø§
        if conf.get("aggregated"):
            continue

        csv_name = conf["csv"]
        xlsx_name = conf["xlsx"]
        df_i, lookup_i = load_data(csv_name, xlsx_name)

        if df_i is None or df_i.empty:
            continue

        df_i = df_i.copy()
        # Ù†Ø¶ÙŠÙ Ø¹Ù…ÙˆØ¯ Ø¨Ø§Ø³Ù… Ø§Ù„Ø¬Ù‡Ø©
        df_i.insert(0, "ENTITY_NAME", name)

        frames.append(df_i)

        # Ø¯Ù…Ø¬ lookup_catalog (Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ Ù†Ø³Ø®Ø© Ù…Ù† ÙƒÙ„ Ø´ÙŠØª)
        for k, v in lookup_i.items():
            if k not in combined_lookup:
                combined_lookup[k] = v

    if frames:
        df_all = pd.concat(frames, ignore_index=True)
    else:
        df_all = pd.DataFrame()

    return df_all, combined_lookup


def series_to_percent(vals: pd.Series):
    vals = pd.to_numeric(vals, errors="coerce").dropna()
    if len(vals) == 0:
        return np.nan
    mx = vals.max()
    if mx <= 5:   # Ø³Ù„Ù… 1-5
        return ((vals - 1) / 4 * 100).mean()
    elif mx <= 10:  # Ø³Ù„Ù… 1-10
        return ((vals - 1) / 9 * 100).mean()
    else:        # Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø§Ù‡Ø²Ø© ÙƒÙ†Ø³Ø¨
        return vals.mean()

def detect_nps(df: pd.DataFrame):
    cand_cols = [c for c in df.columns if ("NPS" in c.upper()) or ("RECOMMEND" in c.upper()) or ("NETPROMOTER" in c.upper())]
    if not cand_cols:
        return np.nan, 0, 0, 0, None
    col = cand_cols[0]
    s = pd.to_numeric(df[col], errors="coerce").dropna()
    if len(s) == 0:
        return np.nan, 0, 0, 0, col
    promoters = (s >= 9).sum()
    passives  = ((s >= 7) & (s <= 8)).sum()
    detract   = (s <= 6).sum()
    total     = len(s)
    promoters_pct = promoters / total * 100
    passives_pct  = passives  / total * 100
    detract_pct   = detract   / total * 100
    nps = promoters_pct - detract_pct
    return nps, promoters_pct, passives_pct, detract_pct, col

def autodetect_metric_cols(df: pd.DataFrame):
    # Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© CSAT Ùˆ CES (Ù‚Ø¯ ØªÙƒÙˆÙ† Dim6.1/Dim6.2 Ø£Ùˆ CSAT/CES Ø£Ùˆ FEES)
    cols_upper = {c.upper(): c for c in df.columns}
    # CSAT
    csat_candidates = [c for c in df.columns if "CSAT" in c.upper()] 

    csat_col = csat_candidates[0] if csat_candidates else None

    #  Fees
    ces_candidates = [c for c in df.columns if "FEES" in c.upper()]
    ces_col = ces_candidates[0] if ces_candidates else None

    # NPS
    nps_candidates = [c for c in df.columns if "NPS" in c.upper()] 
    nps_col = nps_candidates[0] if nps_candidates else None

    return csat_col, ces_col, nps_col

# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¬Ù‡Ø© Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
st.sidebar.title("Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¬Ù‡Ø©")
selected_entity = st.sidebar.selectbox("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¬Ù‡Ø©:", list(ENTITIES.keys()))

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
entity_conf = ENTITIES[selected_entity]       # Ù‡Ù†Ø§ Ù†Ø£Ø®Ø° Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ù‡Ø© (csv/xlsx)
user_conf   = USER_KEYS[selected_entity]      # ÙˆÙ‡Ù†Ø§ Ù†Ø£Ø®Ø° ÙƒÙ„Ù…Ø© Ø§Ù„Ø³Ø± ÙˆØ§Ù„Ø¯ÙˆØ±

correct_password = user_conf["password"]      # â† Ù…Ù† USER_KEYS
is_aggregated    = entity_conf.get("aggregated", False)

# Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
password_input = st.sidebar.text_input(
    "ğŸ” ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù„Ù„Ø¬Ù‡Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©:",
    type="password",
    help="Ù„Ù† ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¥Ù„Ø§ Ø¨Ø¹Ø¯ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„ØµØ­ÙŠØ­Ø©."
)

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù‚Ø¨Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
if not password_input:
    st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ù„Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
    st.stop()
elif password_input != correct_password:
    st.error("âŒ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
    st.stop()
else:
    # Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
    if is_aggregated:
        # Ø¬Ù‡Ø© Ø§Ù„Ø£Ø¯Ù…Ù†: ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø¬Ù‡Ø§Øª Ù…Ø¹Ù‹Ø§
        df, lookup_catalog = load_all_entities()
    else:
        # Ø¬Ù‡Ø© Ø¹Ø§Ø¯ÙŠØ©: ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·
        csv_name = entity_conf["csv"]
        xlsx_name = entity_conf["xlsx"]
        df, lookup_catalog = load_data(csv_name, xlsx_name)

    st.sidebar.markdown(f"**Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:** {selected_entity}")

# Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„ÙÙ„Ø§ØªØ±
ARABIC_FILTER_TITLES = {
    "AGE": "Ø§Ù„Ø¹Ù…Ø±",
    "SERVICE": "Ø§Ù„Ø®Ø¯Ù…Ø©",
    "LANGUAGE": "Ø§Ù„Ù„ØºØ©",
    "PERIOD": "Ø§Ù„ÙØªØ±Ø©",
    "CHANNEL": "Ø§Ù„Ù‚Ù†Ø§Ø©",
    "ENTITY_NAME": "Ø§Ù„Ø¬Ù‡Ø©"
}

st.sidebar.header("ğŸ›ï¸ Ø§Ù„ÙÙ„Ø§ØªØ±")
# Ù†Ø­Ø§ÙˆÙ„ ØªØ·Ø¨ÙŠÙ‚ ØªØ±Ø¬Ù…Ø© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯/Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù€ lookup Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
df_filtered = df.copy()

# Ø³Ù†Ø¹Ø±Ø¶ ÙÙ„Ø§ØªØ± Ù„Ø£ÙƒØ«Ø± Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø´ÙŠÙˆØ¹Ù‹Ø§Ø› ÙˆÙŠÙ…ÙƒÙ† Ø§Ù„ØªÙˆØ³Ø¹ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ø·Ø§Ø¨Ù‚Ø© ÙÙŠ Ø§Ù„Ù€ lookup
candidate_filter_cols = []
# Ø£Ø¨Ø¹Ø§Ø¯ Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠØ© Ø£Ùˆ ÙˆØµÙÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
common_keys = ["Language", "SERVICE", "AGE", "PERIOD", "CHANNEL", "ENTITY_NAME"]
candidate_filter_cols = [c for c in df.columns if any(k in c.upper() for k in common_keys)]

# ÙˆØ¸ÙŠÙØ© Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø¯ÙˆÙ„ lookup Ø¥Ø°Ø§ ØªÙˆÙÙ‘Ø± Ø¨Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯

# ÙˆØ¸ÙŠÙØ© Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø¯ÙˆÙ„ lookup (ØªØ±Ø¨Ø· ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨ÙŠÙ† Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ ÙˆØ§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)
def apply_lookup(column_name: str, s: pd.Series) -> pd.Series:
    key = column_name.strip().upper()

    # 1) ØªØ·Ø§Ø¨Ù‚ ØªØ§Ù… Ø¨ÙŠÙ† Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ ÙˆØ§Ø³Ù… Ø§Ù„Ø´ÙŠØª
    match_key = None
    for k in lookup_catalog.keys():
        if k.strip().upper() == key:
            match_key = k
            break

    # 2) Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ ØªØ·Ø§Ø¨Ù‚ ØªØ§Ù… â†’ Ù†Ø­Ø§ÙˆÙ„ ØªØ·Ø§Ø¨Ù‚ Ø¬Ø²Ø¦ÙŠ
    if match_key is None:
        for k in lookup_catalog.keys():
            if key in k or k in key:
                match_key = k
                break

    if match_key is None:
        return s

    tbl = lookup_catalog[match_key].copy()
    tbl.columns = [str(c).strip().upper() for c in tbl.columns]
    if len(tbl.columns) < 2:
        return s

    code_col = tbl.columns[0]
    name_col = tbl.columns[1]
    map_dict = dict(zip(tbl[code_col].astype(str), tbl[name_col].astype(str)))
    return s.astype(str).map(map_dict).fillna(s)


# Ù†ÙØ­Ø¶Ù‘Ø± Ù†Ø³Ø®Ø© Ù…ØªØ±Ø¬Ù…Ø© Ù„Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„ÙÙ„Ø§ØªØ±
df_filtered_display = df_filtered.copy()
for col in candidate_filter_cols:
    df_filtered_display[col] = apply_lookup(col, df_filtered[col])

with st.sidebar.expander("ØªØ·Ø¨ÙŠÙ‚/Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙ„Ø§ØªØ±"):
    applied_filters = {}

    for col in candidate_filter_cols:

        # Ø·Ø¨Ù‘Ù‚ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… Ø¯Ø§Ø®Ù„ Ø§Ù„ÙÙ„Ø§ØªØ±
        df_filtered[col] = apply_lookup(col, df_filtered[col])

        # Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ù‚Ø§Ø¦Ù…Ø©
        options = df_filtered_display[col].dropna().unique().tolist()
        options_sorted = sorted(options, key=lambda x: str(x))
        default = options_sorted

        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
        label = ARABIC_FILTER_TITLES.get(col.upper(), col)

        # Ø¹Ø±Ø¶ Ø§Ù„ÙÙ„ØªØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ
        sel = st.multiselect(label, options_sorted, default=default)

        applied_filters[col] = sel


# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ±
for col, selected in applied_filters.items():
    if selected:
        df_filtered = df_filtered[df_filtered[col].isin(selected)]

# Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø¹Ø±Ø¶
df_view = df_filtered.copy()

# Ø¹Ù†Ø§ÙˆÙŠÙ† Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹Ù‡Ø§
AR_DIST_TITLES = {
    "AGE": "Ø§Ù„Ø¹Ù…Ø±",
    "SERVICE": "Ø§Ù„Ø®Ø¯Ù…Ø©",
    "LANGUAGE": "Ø§Ù„Ù„ØºØ©",
    "PERIOD": "Ø§Ù„ÙØªØ±Ø©",
    "CHANNEL": "Ø§Ù„Ù‚Ù†Ø§Ø©",
}

# =========================================================
# Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
# =========================================================
if is_aggregated:
    # Ø¬Ù‡Ø© Ø§Ù„Ø£Ø¯Ù…Ù†: Ù†Ø¶ÙŠÙ ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª
    tab_data, tab_sample, tab_kpis, tab_dimensions, tab_services, tab_pareto, tab_admin = st.tabs([
        "ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        "ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©",
        "ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª",
        "ğŸ§© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯",
        "ğŸ“‹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª",
        "ğŸ’¬ Ø§Ù„Ù…Ø²Ø¹Ø¬Ø§Øª",
        "ğŸ“Š Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù‡Ø§Øª"
    ])
else:
    # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¬Ù‡Ø§Øª: Ø¨Ø¯ÙˆÙ† ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª
    tab_data, tab_sample, tab_kpis, tab_dimensions, tab_services, tab_pareto = st.tabs([
        "ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        "ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©",
        "ğŸ“Š Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª",
        "ğŸ§© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯",
        "ğŸ“‹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª",
        "ğŸ’¬ Ø§Ù„Ù…Ø²Ø¹Ø¬Ø§Øª"
    ])
    
# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª + ØªÙ†Ø²ÙŠÙ„
# =========================================================
with tab_data:
    # st.subheader("ğŸ“ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    st.dataframe(df_view, use_container_width=True)
    ts = datetime.now().strftime("%Y-%m-%d_%H%M")
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df_view.to_excel(writer, index=False, sheet_name="Filtered_Data")
    st.download_button("ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)", data=buf.getvalue(),
                       file_name=f"Filtered_Data_{ts}.xlsx",
                       mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©
# =========================================================
with tab_sample:
    st.subheader("ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¹ÙŠÙ†Ø©")
    total = len(df_view)
    st.markdown(
        f"### ğŸ§® Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯: <span style='color:#1E88E5;'>{total:,}</span>",
        unsafe_allow_html=True,
    )

    # Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ù…
    chart_type = st.radio(
        "ğŸ“Š Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ù…", ["Ù…Ø®Ø·Ø· Ø£Ø¹Ù…Ø¯Ø©", "Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ"], index=0, horizontal=True
    )

    # Ø®ÙŠØ§Ø± Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ø¯Ø¯ Ø£Ùˆ Ø§Ù„Ù†Ø³Ø¨Ø© Ø£Ùˆ ÙƒÙ„ÙŠÙ‡Ù…Ø§
    display_mode = st.radio(
        "ğŸ“‹ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø±Ø¶:",
        ["Ø§Ù„Ø¹Ø¯Ø¯ ÙÙ‚Ø·", "Ø§Ù„Ù†Ø³Ø¨Ø© ÙÙ‚Ø·", "Ø§Ù„Ø¹Ø¯Ø¯ + Ø§Ù„Ù†Ø³Ø¨Ø©"],
        horizontal=True,
        index=1,
    )

    # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ Ù„Ù‡Ø§ ØªÙˆØ²ÙŠØ¹ (5 ÙÙ‚Ø·)
    dist_base = ["AGE", "SERVICE", "LANGUAGE", "PERIOD", "CHANNEL"]
    dist_cols = [c for c in candidate_filter_cols if c.upper() in dist_base]

    for col in dist_cols:
        if col not in df_view.columns:
            continue

        counts = (
            df_view[col]
            .value_counts(dropna=True)
            .reset_index()
        )
        counts.columns = [col, "Count"]
        if counts.empty:
            continue

        counts["Percentage"] = (
            counts["Count"] / counts["Count"].sum() * 100
        )

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø­Ø³Ø¨ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        if display_mode == "Ø§Ù„Ø¹Ø¯Ø¯ ÙÙ‚Ø·":
            y_col = "Count"
            y_label = "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯"
            text_col = counts["Count"].astype(str)
        elif display_mode == "Ø§Ù„Ù†Ø³Ø¨Ø© ÙÙ‚Ø·":
            y_col = "Percentage"
            y_label = "Ø§Ù„Ù†Ø³Ø¨Ø© (%)"
            text_col = counts["Percentage"].map("{:.1f}%".format)
        else:  # Ø§Ù„Ø¹Ø¯Ø¯ + Ø§Ù„Ù†Ø³Ø¨Ø©
            y_col = "Count"
            y_label = "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯"
            text_col = counts.apply(
                lambda x: f"{x['Count']} ({x['Percentage']:.1f}%)", axis=1
            )

        # Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ù…Ø®Ø·Ø·
        col_key = col.upper()
        col_label = AR_DIST_TITLES.get(col_key, col)
        title_text = f"ØªÙˆØ²ÙŠØ¹ {col_label}"

        st.markdown(f"### {title_text}")

        # ===== Ø±Ø³Ù… Ø§Ù„Ù…Ø®Ø·Ø· =====
        if chart_type == "Ù…Ø®Ø·Ø· Ø£Ø¹Ù…Ø¯Ø©":
            fig = px.bar(
                counts,
                x=col,
                y=y_col,
                text=text_col,
                color=col,
                color_discrete_sequence=PASTEL,
                title=title_text,
            )
            fig.update_traces(textposition="outside")
            fig.update_layout(
                title={"text": title_text, "x": 0.5},
                xaxis_title="Ø§Ù„ÙØ¦Ø©",
                yaxis_title=y_label,
                showlegend=False,
                height=500,
            )
            fig.update_layout(title_font_size=20)
            st.plotly_chart(fig, use_container_width=True)

        else:  # === Ù…Ø®Ø·Ø· Ø¯Ø§Ø¦Ø±ÙŠ ===
            fig = px.pie(
                counts,
                names=col,
                values="Count",
                hole=0.3,
                color=col,
                color_discrete_sequence=PASTEL,
                title=title_text,
            )

            fig.update_layout(
                title={"text": title_text, "x": 0.5},
                height=500,
            )

            fig.update_layout(title_font_size=20)
            
            # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù†Øµ Ø­Ø³Ø¨ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            if display_mode == "Ø§Ù„Ø¹Ø¯Ø¯ ÙÙ‚Ø·":
                fig.update_traces(
                    textposition="inside",
                    texttemplate="%{label}<br>%{value}",
                )
            elif display_mode == "Ø§Ù„Ù†Ø³Ø¨Ø© ÙÙ‚Ø·":
                fig.update_traces(
                    textposition="inside",
                    texttemplate="%{label}<br>%{percent:.1%}",
                )
            else:  # ÙƒÙ„Ø§Ù‡Ù…Ø§
                fig.update_traces(
                    textposition="inside",
                    texttemplate="%{label}<br>%{value} (%{percent:.1%})",
                )

            st.plotly_chart(fig, use_container_width=True)

        # ===== Ø¬Ø¯ÙˆÙ„ Ù…Ù„Ø®Øµ ØªØ­Øª Ø§Ù„Ù…Ø®Ø·Ø· =====
        st.dataframe(
            counts[[col, "Count", "Percentage"]]
            .rename(
                columns={
                    col: "Ø§Ù„ÙØ¦Ø©",
                    "Count": "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯",
                    "Percentage": "Ø§Ù„Ù†Ø³Ø¨Ø© (%)",
                }
            )
            .style.format({"Ø§Ù„Ù†Ø³Ø¨Ø© (%)": "{:.1f}%"}),
            use_container_width=True,
            hide_index=True,
        )
        st.markdown("---")

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (CSAT / CES / NPS)
# =========================================================
with tab_kpis:
    st.subheader("ğŸ“Š Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
    csat_col, ces_col, nps_col = autodetect_metric_cols(df_view)

    # Ø­Ø³Ø§Ø¨ CSAT
    csat = series_to_percent(df_view.get(csat_col, pd.Series(dtype=float))) if csat_col else np.nan
    # Ø­Ø³Ø§Ø¨ CES/Value
    ces  = series_to_percent(df_view.get(ces_col,  pd.Series(dtype=float))) if ces_col else np.nan
    # Ø­Ø³Ø§Ø¨ NPS
    nps, p_pct, s_pct, d_pct, nps_col = detect_nps(df_view)

    def color_label(score, metric_type):
        if metric_type in ["CSAT", "CES"]:
            if pd.isna(score):           return "#bdc3c7", "ØºÙŠØ± Ù…ØªØ§Ø­"
            if score < 70:               return "#FF6B6B", "Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§"
            elif score < 80:             return "#FFD93D", "Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†"
            elif score < 90:             return "#6BCB77", "Ø¬ÙŠØ¯"
            else:                        return "#4D96FF", "Ù…Ù…ØªØ§Ø²"
        else:  # NPS
            if pd.isna(score):           return "#bdc3c7", "ØºÙŠØ± Ù…ØªØ§Ø­"
            if score < 0:                return "#FF6B6B", "Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§"
            elif score < 30:             return "#FFD93D", "Ø¶Ø¹ÙŠÙ"
            elif score < 60:             return "#6BCB77", "Ø¬ÙŠØ¯"
            else:                        return "#4D96FF", "Ù…Ù…ØªØ§Ø²"

    def gauge(score, title, metric_type):
        color, label = color_label(score, metric_type)
        axis_range = [0, 100] if metric_type in ["CSAT", "CES"] else [-100, 100]
        steps = (
            [{'range': [0, 70], 'color': '#FF6B6B'},
             {'range': [70, 80], 'color': '#FFD93D'},
             {'range': [80, 90], 'color': '#6BCB77'},
             {'range': [90, 100], 'color': '#4D96FF'}]
            if metric_type in ["CSAT", "CES"]
            else [{'range': [-100, 0], 'color': '#FF6B6B'},
                  {'range': [0, 30], 'color': '#FFD93D'},
                  {'range': [30, 60], 'color': '#6BCB77'},
                  {'range': [60, 100], 'color': '#4D96FF'}]
        )
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=0 if pd.isna(score) else float(score),
            number={'suffix': "Ùª" if metric_type != "NPS" else ""},
            title={'text': title, 'font': {'size': 18}},
            gauge={
                'axis': {'range': axis_range},
                'bar': {'color': color},
                'steps': steps
            }
        ))
        fig.update_layout(height=300, margin=dict(l=30, r=30, t=60, b=30))
        return fig, label

    c1, c2, c3 = st.columns(3)
    fig1, lab1 = gauge(csat, "Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¹Ø§Ù…Ø© (CSAT)", "CSAT")
    fig2, lab2 = gauge(ces,  "Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø¬Ù‡Ø¯/Ø§Ù„ØªÙƒÙ„ÙØ© (CES/Value)", "CES")
    fig3, lab3 = gauge(nps,  "ØµØ§ÙÙŠ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ±ÙˆÙŠØ¬ (NPS)", "NPS")
    c1.plotly_chart(fig1, use_container_width=True)
    c1.markdown(f"**Ø§Ù„ØªÙØ³ÙŠØ±:** {lab1}")
    if csat_col: c1.caption(f"Ø§Ù„Ù…ØµØ¯Ø±: {csat_col}")
    c2.plotly_chart(fig2, use_container_width=True)
    c2.markdown(f"**Ø§Ù„ØªÙØ³ÙŠØ±:** {lab2}")
    if ces_col: c2.caption(f"Ø§Ù„Ù…ØµØ¯Ø±: {ces_col}")
    c3.plotly_chart(fig3, use_container_width=True)
    c3.markdown(f"**Ø§Ù„ØªÙØ³ÙŠØ±:** {lab3}")
    if nps_col: c3.caption(f"Ø§Ù„Ù…ØµØ¯Ø±: {nps_col}")
    c3.markdown(f"Ø§Ù„Ù…Ø±ÙˆØ¬ÙˆÙ†: {p_pct:.1f}% | Ø§Ù„Ù…Ø­Ø§ÙŠØ¯ÙˆÙ†: {s_pct:.1f}% | Ø§Ù„Ù…Ø¹Ø§Ø±Ø¶ÙˆÙ†: {d_pct:.1f}%", unsafe_allow_html=True)

    # =========================================================
    # ğŸ¨ ÙˆØ³ÙŠÙ„ØªØ§ Ø§Ù„Ø¥ÙŠØ¶Ø§Ø­ (Legends)
    # =========================================================
    legend_html = """
    <div style='background-color:#f9f9f9;border:1px solid #ddd;border-radius:10px;padding:12px;margin-top:15px;'>
        <h4 style='margin-bottom:8px;'>ğŸ¨ ÙˆØ³ÙŠÙ„Ø© Ø§Ù„Ø¥ÙŠØ¶Ø§Ø­ â€” Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© / Ø§Ù„Ù‚ÙŠÙ…Ø©</h4>
        ğŸ”´ Ø£Ù‚Ù„ Ù…Ù† 70Ùª â€” Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§<br>
        ğŸŸ¡ Ù…Ù† 70 Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 80Ùª â€” Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†<br>
        ğŸŸ¢ Ù…Ù† 80 Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 90Ùª â€” Ø¬ÙŠØ¯<br>
        ğŸ”µ 90Ùª ÙØ£ÙƒØ«Ø± â€” Ù…Ù…ØªØ§Ø²
    </div>
    <div style='background-color:#f9f9f9;border:1px solid #ddd;border-radius:10px;padding:12px;margin-top:10px;'>
        <h4 style='margin-bottom:8px;'>ğŸ¯ ÙˆØ³ÙŠÙ„Ø© Ø§Ù„Ø¥ÙŠØ¶Ø§Ø­ â€” ØµØ§ÙÙŠ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ±ÙˆÙŠØ¬ (NPS)</h4>
        ğŸ”´ Ø£Ù‚Ù„ Ù…Ù† 0 â€” Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ù‹Ø§ (Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ø§Ø±Ø¶ÙŠÙ† Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ù…Ø±ÙˆØ¬ÙŠÙ†)<br>
        ğŸŸ¡ Ù…Ù† 0 Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 30 â€” Ø¶Ø¹ÙŠÙ (Ø±Ø¶Ø§ Ù…Ø­Ø¯ÙˆØ¯)<br>
        ğŸŸ¢ Ù…Ù† 30 Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 60 â€” Ø¬ÙŠØ¯ (Ø±Ø¶Ø§ Ø¹Ø§Ù…)<br>
        ğŸ”µ 60 ÙØ£ÙƒØ«Ø± â€” Ù…Ù…ØªØ§Ø² (ÙˆÙ„Ø§Ø¡ Ù…Ø±ØªÙØ¹ Ø¬Ø¯Ù‹Ø§)
    </div>
    """
    st.markdown(legend_html, unsafe_allow_html=True)

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (3 Ø£Ø¨Ø¹Ø§Ø¯ ÙÙ‚Ø·)
# =========================================================
with tab_dimensions:
    # st.subheader("ğŸ§© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯")

    # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ø£ Ø¨Ù€ "DimX." (Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø¯Ø§Ø®Ù„ ÙƒÙ„ Ø¨Ø¹Ø¯)
    dim_subcols = [c for c in df_view.columns if re.match(r"Dim\d+\.", str(c).strip())]
    if not dim_subcols:
        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙØ±Ø¹ÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ù…Ø«Ù„ Dim1.1 Ø£Ùˆ Dim2.3).")
    else:
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…ØªÙˆØ³Ø· Ù„ÙƒÙ„ Ø¨Ø¹Ø¯ Ø±Ø¦ÙŠØ³ÙŠ (Dim1, Dim2, Dim3...) â€” Ù†Ù„ØªÙ‚Ø· Ù…Ø§ Ù‡Ùˆ Ù…ØªØ§Ø­
        main_dim_map = {}
        for i in range(1, 6):
            sub = [c for c in df_view.columns if str(c).startswith(f"Dim{i}.")]
            if sub:
                main_dim_map[f"Dim{i}"] = df_view[sub].apply(pd.to_numeric, errors="coerce").mean(axis=1)

        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ø¨Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
        summary = []
        for dim, series in main_dim_map.items():
            score = series_to_percent(series)
            summary.append({"Dimension": dim, "Score": score})

        dims = pd.DataFrame(summary).dropna()
        if dims.empty:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ÙƒØ§ÙÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯.")
        else:
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø­Ø³Ø¨ Ø§Ù„Ø±Ù‚Ù… (Dim1, Dim2...)
            dims["Order"] = dims["Dimension"].str.extract(r"(\d+)").astype(float)
            dims = dims.sort_values("Order").reset_index(drop=True)

            # ğŸ”„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù† ÙˆØ±Ù‚Ø© "Questions" ÙÙŠ Ù…Ù„Ù Excel Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª
            for sheet_name in lookup_catalog.keys():
                if "QUESTION" in sheet_name:  # ÙŠÙ„ØªÙ‚Ø· Question Ø£Ùˆ Questions
                    qtbl = lookup_catalog[sheet_name].copy()
                    qtbl.columns = [str(c).strip().upper() for c in qtbl.columns]

                    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ ÙˆØ¹Ù…ÙˆØ¯ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ
                    code_col = next((c for c in qtbl.columns if any(k in c for k in ["DIM", "CODE", "QUESTION", "ID"])), None)
                    name_col = next((c for c in qtbl.columns if any(k in c for k in ["ARABIC", "NAME", "LABEL", "TEXT"])), None)

                    if code_col and name_col:
                        def _norm(s):
                            return s.astype(str).str.upper().str.replace(r"\s+", "", regex=True)

                        code_series = _norm(qtbl[code_col])
                        name_series = qtbl[name_col].astype(str)
                        map_dict = dict(zip(code_series, name_series))

                        # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
                        dims["Dimension"] = (
                            _norm(dims["Dimension"])
                            .map(map_dict)
                            .fillna(dims["Dimension"])
                        )
                    break  # ØªÙˆÙ‚Ù Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©

            # ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø­Ø³Ø¨ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            def cat(score):
                if score < 70:  return "ğŸ”´ Ø¶Ø¹ÙŠÙ"
                elif score < 80: return "ğŸŸ¡ Ù…ØªÙˆØ³Ø·"
                elif score < 90: return "ğŸŸ¢ Ø¬ÙŠØ¯"
                else:            return "ğŸ”µ Ù…Ù…ØªØ§Ø²"
            dims["Category"] = dims["Score"].apply(cat)

            # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯
            fig = px.bar(
                dims, x="Dimension", y="Score", text="Score", color="Category",
                color_discrete_map={
                    "ğŸ”´ Ø¶Ø¹ÙŠÙ": "#FF6B6B",
                    "ğŸŸ¡ Ù…ØªÙˆØ³Ø·": "#FFD93D",
                    "ğŸŸ¢ Ø¬ÙŠØ¯":   "#6BCB77",
                    "ğŸ”µ Ù…Ù…ØªØ§Ø²": "#4D96FF"
                },
                title="<span style='font-size:28px; font-weight:bold;'>ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯</span>"
            )
            fig.update_traces(texttemplate="%{text:.1f}%", textposition="outside")
            fig.update_layout(
                title={
                    'text': "<span style='font-size:22px; font-weight:bold;'>ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯</span>",
                    'x': 0.5,  # Ø§Ù„Ù…Ù†ØªØµÙ
                    'xanchor': 'center'
                },
                yaxis=dict(range=[0, 100]),
                xaxis_title="Ø§Ù„Ø¨Ø¹Ø¯",
                yaxis_title="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© (%)"
            )

            st.plotly_chart(fig, use_container_width=True)
            # ÙˆØ³ÙŠÙ„Ø© Ø§Ù„Ø¥ÙŠØ¶Ø§Ø­ Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ù„ØºØ©
            st.markdown(
                """
                **ğŸ—‚ï¸ ÙˆØ³ÙŠÙ„Ø© Ø§Ù„Ø¥ÙŠØ¶Ø§Ø­:**
                - ğŸ”´ Ø£Ù‚Ù„ Ù…Ù† 70Ùª â€” Ø¶Ø¹ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø¡  
                - ğŸŸ¡ Ù…Ù† 70Ùª Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 80Ùª â€” Ù…ØªÙˆØ³Ø·  
                - ğŸŸ¢ Ù…Ù† 80Ùª Ø¥Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 90Ùª â€” Ø¬ÙŠØ¯  
                - ğŸ”µ 90Ùª ÙØ£ÙƒØ«Ø± â€” Ù…Ù…ØªØ§Ø²  
                """,
            unsafe_allow_html=True)
            # Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
            st.dataframe(
                dims[["Dimension", "Score"]]
                .rename(columns={"Dimension": "Ø§Ù„Ø¨Ø¹Ø¯", "Score": "Ø§Ù„Ù†Ø³Ø¨Ø© (%)"})
                .style.format({"Ø§Ù„Ù†Ø³Ø¨Ø© (%)": "{:.1f}%"}),
                use_container_width=True,
                hide_index=True
            )

# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
# =========================================================
with tab_services:
    st.subheader("ğŸ“‹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª")
    if "SERVICE" not in df_view.columns:
        st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø®Ø¯Ù…Ø§Øª (SERVICE).")
    else:
        csat_col, ces_col, _ = autodetect_metric_cols(df_view)
        work = df_view.copy()
        if csat_col:
            work["Ø³Ø¹Ø§Ø¯Ø© (%)"] = (pd.to_numeric(work[csat_col], errors="coerce") - 1) * 25
        if ces_col:
            work["Ù‚ÙŠÙ…Ø© (%)"] = (pd.to_numeric(work[ces_col], errors="coerce") - 1) * 25

        # NPS Ù„ÙƒÙ„ Ø®Ø¯Ù…Ø© Ø¥Ù† ÙˆÙØ¬Ø¯ Ø¹Ù…ÙˆØ¯ NPS
        nps_cols = [c for c in df_view.columns if "NPS" in c.upper() or "RECOMMEND" in c.upper()]
        if nps_cols:
            work["NPS_VAL"] = pd.to_numeric(work[nps_cols[0]], errors="coerce")
            nps_summary = []
            for svc, g in work.groupby("SERVICE"):
                s = g["NPS_VAL"].dropna()
                if len(s) == 0:
                    nps_summary.append((svc, np.nan))
                    continue
                promoters = (s >= 9).sum()
                detractors = (s <= 6).sum()
                total = len(s)
                nps_value = ((promoters - detractors) / total) * 100
                nps_summary.append((svc, nps_value))
            nps_df = pd.DataFrame(nps_summary, columns=["SERVICE", "NPS (%)"])
        else:
            nps_df = pd.DataFrame(columns=["SERVICE", "NPS (%)"])

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯
        agg_dict = {}
        if "Ø³Ø¹Ø§Ø¯Ø© (%)" in work.columns: agg_dict["Ø³Ø¹Ø§Ø¯Ø© (%)"] = "mean"
        if "Ù‚ÙŠÙ…Ø© (%)" in work.columns:  agg_dict["Ù‚ÙŠÙ…Ø© (%)"]  = "mean"
        if csat_col:                   agg_dict[csat_col]    = "count"

        if not agg_dict:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø©.")
        else:
            summary = work.groupby("SERVICE").agg(agg_dict).reset_index()
            if csat_col and csat_col in summary.columns:
                summary.rename(columns={csat_col: "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯"}, inplace=True)

            # Ø¯Ù…Ø¬ NPS
            if not nps_df.empty:
                summary = summary.merge(nps_df, on="SERVICE", how="left")

            # ØªØ±Ø¬Ù…Ø© Ø§Ø³Ù… Ø§Ù„Ø®Ø¯Ù…Ø© Ø¹Ø¨Ø± lookup (Ø¥Ù† ÙˆØ¬Ø¯ sheet Ø¨Ø§Ø³Ù… SERVICE)
            if "SERVICE" in lookup_catalog:
                tbl = lookup_catalog["SERVICE"].copy()
                tbl.columns = [str(c).strip().upper() for c in tbl.columns]
                code_col = next((c for c in tbl.columns if "CODE" in c or "SERVICE" in c), None)
                ar_col   = next((c for c in tbl.columns if ("ARABIC" in c) or ("SERVICE2" in c)), None)
                if code_col and ar_col:
                    name_map = dict(zip(tbl[code_col].astype(str), tbl[ar_col].astype(str)))
                    summary["SERVICE"] = summary["SERVICE"].astype(str).map(name_map).fillna(summary["SERVICE"])

            # ÙÙ„ØªØ±Ø© Ø¥Ù„Ù‰ Ø®Ø¯Ù…Ø§Øª Ø¨Ø¹Ø¯Ø¯ Ø±Ø¯ÙˆØ¯ ÙƒØ§ÙÙ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ: 30)
            if "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯" in summary.columns:
                summary = summary[summary["Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯"] >= 30]

            # ØªØ±ØªÙŠØ¨
            sort_key = "Ø³Ø¹Ø§Ø¯Ø© (%)" if "Ø³Ø¹Ø§Ø¯Ø© (%)" in summary.columns else ("Ù‚ÙŠÙ…Ø© (%)" if "Ù‚ÙŠÙ…Ø© (%)" in summary.columns else None)
            if sort_key:
                summary = summary.sort_values(sort_key, ascending=False)

            # âœ… ØªÙ„ÙˆÙŠÙ† Ø§Ù„Ø®Ù„Ø§ÙŠØ§ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© ÙˆØ§Ù„Ù‚ÙŠÙ…Ø© ÙÙ‚Ø·)
            def color_cells(val):
                try:
                    v = float(val)
                    if v < 70:
                        color = "#FF6B6B"  # Ø£Ø­Ù…Ø±
                    elif v < 80:
                        color = "#FFD93D"  # Ø£ØµÙØ±
                    elif v < 90:
                        color = "#6BCB77"  # Ø£Ø®Ø¶Ø±
                    else:
                        color = "#4D96FF"  # Ø£Ø²Ø±Ù‚
                    return f"background-color:{color};color:black"
                except:
                    return ""

            # ğŸ“‹ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ format Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø©
            format_dict = {}
            if "Ø³Ø¹Ø§Ø¯Ø© (%)" in summary.columns:
                format_dict["Ø³Ø¹Ø§Ø¯Ø© (%)"] = "{:.1f}%"
            if "Ù‚ÙŠÙ…Ø© (%)" in summary.columns:
                format_dict["Ù‚ÙŠÙ…Ø© (%)"] = "{:.1f}%"
            if "NPS (%)" in summary.columns:
                format_dict["NPS (%)"] = "{:.1f}%"
            if "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯" in summary.columns:
                format_dict["Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯"] = "{:,.0f}"

            subset_cols = [c for c in ["Ø³Ø¹Ø§Ø¯Ø© (%)", "Ù‚ÙŠÙ…Ø© (%)"] if c in summary.columns]

            # ğŸ“‹ Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„
            styled_table = (
                summary.style
                .format(format_dict)
                .applymap(color_cells, subset=subset_cols)
            )
            st.dataframe(styled_table, use_container_width=True)

            # ğŸ›ˆ Ù…Ù„Ø§Ø­Ø¸Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¨Ø§Ù„Ù„ØºØªÙŠÙ†
            st.markdown(
                """
                **â„¹ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©:**  
                ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ **30 Ø±Ø¯Ù‹Ø§ Ø£Ùˆ Ø£ÙƒØ«Ø± ÙÙ‚Ø·** Ù„Ø¶Ù…Ø§Ù† Ø¯Ù‚Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬.  
                """
            )

            # Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© (Ø³Ø¹Ø§Ø¯Ø©/Ù‚ÙŠÙ…Ø©)
            if "Ø³Ø¹Ø§Ø¯Ø© (%)" in summary.columns or "Ù‚ÙŠÙ…Ø© (%)" in summary.columns:
                melted = summary.melt(
                    id_vars=["SERVICE"],
                    value_vars=[v for v in ["Ø³Ø¹Ø§Ø¯Ø© (%)", "Ù‚ÙŠÙ…Ø© (%)"] if v in summary.columns],
                    var_name="Ø§Ù„Ù…Ø¤Ø´Ø±",
                    value_name="Ø§Ù„Ù‚ÙŠÙ…Ø©"
                )

                fig = px.bar(
                    melted,
                    x="SERVICE",
                    y="Ø§Ù„Ù‚ÙŠÙ…Ø©",
                    color="Ø§Ù„Ù…Ø¤Ø´Ø±",
                    barmode="group",
                    text="Ø§Ù„Ù‚ÙŠÙ…Ø©",
                    color_discrete_sequence=PASTEL,
                    title="Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¤Ø´Ø±ÙŠ Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© ÙˆØ§Ù„Ù‚ÙŠÙ…Ø© Ø­Ø³Ø¨ Ø§Ù„Ø®Ø¯Ù…Ø©"
                )
                fig.update_traces(texttemplate="%{text:.1f}%", textposition="outside")

                fig.update_layout(
                    yaxis=dict(range=[0, 100]),
                    xaxis_title="Ø§Ù„Ø®Ø¯Ù…Ø©",
                    yaxis_title="Ø§Ù„Ù†Ø³Ø¨Ø© (%)"
                )

                # ğŸ”¥ ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø¹Ù†ÙˆØ§Ù† + ØªÙˆØ³ÙŠØ·Ù‡
                fig.update_layout(
                    title={
                        "text": "ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¤Ø´Ø±ÙŠ Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© ÙˆØ§Ù„Ù‚ÙŠÙ…Ø© Ø­Ø³Ø¨ Ø§Ù„Ø®Ø¯Ù…Ø©",
                        "x": 0.5,
                        "y": 0.95,
                        "xanchor": "center",
                        "yanchor": "top"
                    },
                    title_font_size=20
                )
                st.plotly_chart(fig, use_container_width=True)


# =========================================================
# ğŸ’¬ ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø±Ø¶Ø§ (Most_Unsat) Ø¨Ø·Ø±ÙŠÙ‚Ø© Pareto
# =========================================================
with tab_pareto:
    st.subheader("ğŸ’¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø²Ø¹Ø¬Ø§Øª")

    unsat_col = next((c for c in df_view.columns if "MOST_UNSAT" in c.upper()), None)
    if not unsat_col:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…ÙˆØ¯ Most_Unsat ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
    else:
        data_unsat = df_view[[unsat_col]].copy()
        data_unsat.columns = ["Comment"]
        data_unsat["Comment"] = data_unsat["Comment"].astype(str).str.strip()

        # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
        exclude_terms = ["", " ", "Ù„Ø§ ÙŠÙˆØ¬Ø¯", "Ù„Ø§ÙŠÙˆØ¬Ø¯", "Ù„Ø§Ø´ÙŠØ¡", "Ù„Ø§ Ø´ÙŠØ¡",
                         "none", "no", "nothing", "nil", "Ø¬ÙŠØ¯", "Ù…Ù…ØªØ§Ø²", "ok", "ØªÙ…Ø§Ù…", "great"]
        data_unsat = data_unsat[~data_unsat["Comment"].str.lower().isin([t.lower() for t in exclude_terms])]
        data_unsat = data_unsat[data_unsat["Comment"].apply(lambda x: len(x.split()) >= 2)]

        if data_unsat.empty:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù†ØµÙŠØ© ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ.")
        else:
            # ğŸ”¹ ØªØµÙ†ÙŠÙ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø­Ø§ÙˆØ±
            themes = {
                "Ø§Ù„Ø³Ø±Ø¹Ø© / Ø§Ù„Ø£Ø¯Ø§Ø¡": ["Ø¨Ø·Ø¡", "ØªØ£Ø®ÙŠØ±", "Ø§Ù†ØªØ¸Ø§Ø±", "delay", "slow", "Ø²Ù…Ù†", "ÙˆÙ‚Øª"],
                "Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ / Ø§Ù„Ù…Ù†ØµØ©": ["ØªØ·Ø¨ÙŠÙ‚", "app", "Ù…Ù†ØµØ©", "system", "Ù…ÙˆÙ‚Ø¹", "Ø¨ÙˆØ§Ø¨Ø©", "ØµÙØ­Ø©"],
                "Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª / Ø§Ù„Ø®Ø·ÙˆØ§Øª": ["Ø¥Ø¬Ø±Ø§Ø¡", "Ø§Ø¬Ø±Ø§Ø¡", "Ø¹Ù…Ù„ÙŠØ©", "process", "Ø®Ø·ÙˆØ§Øª", "Ù…Ø±Ø§Ø­Ù„", "Ù†Ù…ÙˆØ°Ø¬"],
                "Ø§Ù„Ø±Ø³ÙˆÙ… / Ø§Ù„Ø¯ÙØ¹": ["Ø±Ø³ÙˆÙ…", "Ø¯ÙØ¹", "fee", "ØªÙƒÙ„ÙØ©", "Ø³Ø¯Ø§Ø¯", "pay"],
                "Ø§Ù„ØªÙˆØ§ØµÙ„ / Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙÙ†ÙŠ": ["Ø±Ø¯", "ØªÙˆØ§ØµÙ„", "Ø§ØªØµØ§Ù„", "support", "response", "Ù…Ø³Ø§Ù†Ø¯Ø©", "Ù…Ø³Ø§Ø¹Ø¯Ø©"],
                "Ø§Ù„ÙˆØ¶ÙˆØ­ / Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª": ["Ù…Ø¹Ù„ÙˆÙ…Ø©", "Ø¥ÙŠØ¶Ø§Ø­", "clarity", "instructions", "Ø¨ÙŠØ§Ù†Ø§Øª", "Ø´Ø±Ø­"],
                "Ø§Ù„Ø£Ù…Ø§Ù† / Ø§Ù„Ø¯Ø®ÙˆÙ„": ["ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ±", "Ø¯Ø®ÙˆÙ„", "login", "ØªØ­Ù‚Ù‚", "Ø£Ù…Ø§Ù†"]
            }

            def classify_text(txt):
                t = txt.lower()
                for theme, keywords in themes.items():
                    if any(k.lower() in t for k in keywords):
                        return theme
                return "ØºÙŠØ± Ù…ØµÙ†Ù‘Ù"

            data_unsat["Ø§Ù„Ù…Ø­ÙˆØ±"] = data_unsat["Comment"].apply(classify_text)
            data_unsat = data_unsat[data_unsat["Ø§Ù„Ù…Ø­ÙˆØ±"] != "ØºÙŠØ± Ù…ØµÙ†Ù‘Ù"]

            # ğŸ”¢ ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø­ÙˆØ± + Ø¶Ù…Ù‘ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø¨ÙØ§ØµÙ„ "/"
            summary = data_unsat.groupby("Ø§Ù„Ù…Ø­ÙˆØ±").agg({
                "Comment": lambda x: " / ".join(x.tolist())
            }).reset_index()

            summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"] = summary["Comment"].apply(lambda x: len(x.split("/")))
            summary = summary.sort_values("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª", ascending=False).reset_index(drop=True)
            summary["Ø§Ù„Ù†Ø³Ø¨Ø© (%)"] = summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"] / summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"].sum() * 100
            summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] = summary["Ø§Ù„Ù†Ø³Ø¨Ø© (%)"].cumsum()
            summary["Ø§Ù„Ù„ÙˆÙ†"] = np.where(summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] <= 80, "#E74C3C", "#BDC3C7")

            # âœ… Ø£ÙˆÙ„ Ø¨Ù†Ø¯ ÙŠØªØ¬Ø§ÙˆØ² 80Ùª ÙŠÙƒÙˆÙ† Ø£Ø­Ù…Ø± Ø£ÙŠØ¶Ù‹Ø§
            if not summary[summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] > 80].empty:
                first_above = summary[summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"] > 80].index[0]
                summary.loc[first_above, "Ø§Ù„Ù„ÙˆÙ†"] = "#E74C3C"

            # ğŸ§¾ Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„
            st.dataframe(
                summary[["Ø§Ù„Ù…Ø­ÙˆØ±", "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª", "Ø§Ù„Ù†Ø³Ø¨Ø© (%)", "Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)", "Comment"]]
                .rename(columns={"Comment": "Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª (Ù…Ø¬Ù…Ø¹Ø©)"}).style.format({
                    "Ø§Ù„Ù†Ø³Ø¨Ø© (%)": "{:.1f}%",
                    "Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)": "{:.1f}%"
                }),
                use_container_width=True,
                hide_index=True
            )

            # ğŸ“Š Ø±Ø³Ù… Pareto
            fig = go.Figure()
            fig.add_bar(
                x=summary["Ø§Ù„Ù…Ø­ÙˆØ±"],
                y=summary["Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"],
                marker_color=summary["Ø§Ù„Ù„ÙˆÙ†"],
                name="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"
            )
            fig.add_scatter(
                x=summary["Ø§Ù„Ù…Ø­ÙˆØ±"],
                y=summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"],
                yaxis="y2",
                mode="lines+markers+text",
                name="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)",
                text=[f"{v:.1f}%" for v in summary["Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)"]],
                textposition="top center",
                line=dict(color="#2E86DE", width=3)
            )
            fig.update_layout(
                title={
                "text": "ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø±ÙŠØªÙˆ - Ø§Ù„Ù…Ø­Ø§ÙˆØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©",
                    "x": 0.5,
                    "y": 0.95,
                    "xanchor": "center",
                    "yanchor": "top"
                },
                title_font_size=20,
                xaxis=dict(title="Ø§Ù„Ù…Ø­ÙˆØ±", tickangle=-15),
                yaxis=dict(title="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª"),
                yaxis2=dict(title="Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© (%)", overlaying="y", side="right", range=[0, 110]),
                height=600,
                bargap=0.3,
                legend=dict(orientation="h", y=-0.2)
            )
            st.plotly_chart(fig, use_container_width=True)
            # ğŸ“¥ Ø²Ø± ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Pareto (Excel)
            pareto_buffer = io.BytesIO()
            with pd.ExcelWriter(pareto_buffer, engine="openpyxl") as writer:
                summary.to_excel(writer, index=False, sheet_name="Pareto_Results")

            pareto_buffer.seek(0)  # Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©

            st.download_button(
                label="ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Pareto (Excel)",
                data=pareto_buffer.getvalue(),
                file_name=f"Pareto_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø®Ø§Øµ Ù„Ù„Ø£Ù…Ø§Ù†Ø© Ø§Ù„Ø¹Ø§Ù…Ø©: Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ù‡Ø§Øª ÙÙŠ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø£Ø¨Ø¹Ø§Ø¯
# =========================================================
if is_aggregated:
    with tab_admin:
        st.subheader("ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ù‡Ø§Øª ÙÙŠ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ§Ù„Ø£Ø¨Ø¹Ø§Ø¯")

        # ØªØ£ÙƒØ¯ Ø£Ù† Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„Ø¬Ù‡Ø© Ù…ÙˆØ¬ÙˆØ¯
        if "ENTITY_NAME" not in df_view.columns:
            st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ ENTITY_NAME ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ù‘Ø¹Ø©.")
        else:
            # ÙƒØ´Ù Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ (CSAT / CES / NPS) ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
            csat_col, ces_col, nps_col = autodetect_metric_cols(df_view)

            work = df_view.copy()

            # ğŸ”¹ ØªØ¬Ù…ÙŠØ¹ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ÙƒÙ„ Ø¬Ù‡Ø©
            rows = []
            for ent, g in work.groupby("ENTITY_NAME"):
                row = {"Ø§Ù„Ø¬Ù‡Ø©": ent, "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯": len(g)}

                if csat_col:
                    row["Ø³Ø¹Ø§Ø¯Ø© (%)"] = series_to_percent(g[csat_col])
                if ces_col:
                    row["Ù‚ÙŠÙ…Ø© (%)"] = series_to_percent(g[ces_col])

                nps_val, _, _, _, _ = detect_nps(g)
                row["NPS (%)"] = nps_val

                rows.append(row)

            kpi_df = pd.DataFrame(rows)

            if kpi_df.empty:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.")
            else:
                # ğŸ“‹ Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø¹ ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø¨Ø³ÙŠØ·Ø©
                kpi_display = kpi_df.copy()
                for c in ["Ø³Ø¹Ø§Ø¯Ø© (%)", "Ù‚ÙŠÙ…Ø© (%)", "NPS (%)"]:
                    if c in kpi_display.columns:
                        kpi_display[c] = kpi_display[c].round(1)

                st.markdown("### ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù‡Ø©")
                st.dataframe(
                    kpi_display.style.format({
                        "Ø³Ø¹Ø§Ø¯Ø© (%)": "{:.1f}%",
                        "Ù‚ÙŠÙ…Ø© (%)": "{:.1f}%",
                        "NPS (%)": "{:.1f}%",
                        "Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø¯ÙˆØ¯": "{:,.0f}"
                    }),
                    use_container_width=True,
                    hide_index=True
                )

                # ğŸ“Š Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø³Ø¹Ø§Ø¯Ø©/Ù‚ÙŠÙ…Ø©/NPS Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù‡Ø©
                metric_cols = [c for c in ["Ø³Ø¹Ø§Ø¯Ø© (%)", "Ù‚ÙŠÙ…Ø© (%)", "NPS (%)"] if c in kpi_df.columns]
                if metric_cols:
                    melted_kpi = kpi_df.melt(
                        id_vars=["Ø§Ù„Ø¬Ù‡Ø©"],
                        value_vars=metric_cols,
                        var_name="Ø§Ù„Ù…Ø¤Ø´Ø±",
                        value_name="Ø§Ù„Ù‚ÙŠÙ…Ø©"
                    )

                    fig_kpi = px.bar(
                        melted_kpi,
                        x="Ø§Ù„Ø¬Ù‡Ø©",
                        y="Ø§Ù„Ù‚ÙŠÙ…Ø©",
                        color="Ø§Ù„Ù…Ø¤Ø´Ø±",
                        barmode="group",
                        text="Ø§Ù„Ù‚ÙŠÙ…Ø©",
                        title="Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù‡Ø©"
                    )
                    fig_kpi.update_traces(texttemplate="%{text:.1f}%", textposition="outside")
                    fig_kpi.update_layout(
                        yaxis=dict(range=[0, 100]),
                        xaxis_title="Ø§Ù„Ø¬Ù‡Ø©",
                        yaxis_title="Ø§Ù„Ù†Ø³Ø¨Ø© (%)",
                        legend=dict(orientation="h", y=-0.2)
                    )
                    st.plotly_chart(fig_kpi, use_container_width=True)
if is_aggregated:
    with tab_admin:
        st.subheader("ğŸ“Š Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù‡Ø§Øª")

        # Ù‡Ù†Ø§ ØªØ¶Ø¹ Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª ÙÙŠ KPIs ÙˆØ§Ù„Ø£Ø¨Ø¹Ø§Ø¯
        # Ù…Ø«Ø§Ù„ Ø¨Ø³ÙŠØ·:
        if "ENTITY_NAME" not in df_view.columns:
            st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ ENTITY_NAME ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        else:
            st.write("Ù‡Ù†Ø§ Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù‡Ø§Øª...")
            # Ø¶Ø¹ ÙƒÙˆØ¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª
# =========================================================
# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£Ø¯Ù…Ù†: Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ù‡Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Dim1, Dim2, ...)
# =========================================================
if is_aggregated:
    with tab_admin:
        st.subheader("ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ù‡Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Dim1, Dim2, ...)")

        if "ENTITY_NAME" not in df_view.columns:
            st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ ENTITY_NAME ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ù‘Ø¹Ø©.")
        else:
            # 1ï¸âƒ£ Ù†Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ DimX. (Ù…Ø«Ù„ Dim1.1 / Dim2.3)
            dim_subcols = [c for c in df_view.columns if re.match(r"Dim\d+\.", str(c).strip())]

            if not dim_subcols:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙØ±Ø¹ÙŠØ© Ù„Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ù…Ø«Ù„ Dim1.1 Ø£Ùˆ Dim2.3) ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
            else:
                # Ù†Ø³ØªØ®Ø±Ø¬ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© (1,2,3,...) Ù…Ù† DimX.Y
                main_ids = sorted({
                    int(re.match(r"Dim(\d+)\.", str(c).strip()).group(1))
                    for c in dim_subcols
                    if re.match(r"Dim(\d+)\.", str(c).strip())
                })

                # 2ï¸âƒ£ Ø­Ø³Ø§Ø¨ Ù†ØªÙŠØ¬Ø© ÙƒÙ„ Ø¨ÙØ¹Ø¯ Ø±Ø¦ÙŠØ³ÙŠ Ù„ÙƒÙ„ Ø¬Ù‡Ø©
                rows = []
                for ent, g in df_view.groupby("ENTITY_NAME"):
                    for i in main_ids:
                        # ÙƒÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ø£ Ø¨Ù€ Dim{i}.
                        sub = [c for c in g.columns if str(c).startswith(f"Dim{i}.")]
                        if not sub:
                            continue

                        # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ© Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¨Ø¹Ø¯
                        dim_series = g[sub].apply(pd.to_numeric, errors="coerce").mean(axis=1)
                        score = series_to_percent(dim_series)

                        rows.append({
                            "Ø§Ù„Ø¬Ù‡Ø©": ent,
                            "Dimension": f"Dim{i}",
                            "Score": score
                        })

                dim_comp_df = pd.DataFrame(rows).dropna(subset=["Score"])

                if dim_comp_df.empty:
                    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„ÙƒÙ„ Ø¬Ù‡Ø©.")
                else:
                    # 3ï¸âƒ£ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù† ÙˆØ±Ù‚Ø© Questions (Ù†ÙØ³ Ù…Ù†Ø·Ù‚ ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯)
                    for sheet_name in lookup_catalog.keys():
                        if "QUESTION" in sheet_name.upper():  # Question / Questions
                            qtbl = lookup_catalog[sheet_name].copy()
                            qtbl.columns = [str(c).strip().upper() for c in qtbl.columns]

                            code_col = next(
                                (c for c in qtbl.columns if any(k in c for k in ["DIM", "CODE", "QUESTION", "ID"])),
                                None
                            )
                            name_col = next(
                                (c for c in qtbl.columns if any(k in c for k in ["ARABIC", "NAME", "LABEL", "TEXT"])),
                                None
                            )

                            if code_col and name_col:
                                def _norm(s):
                                    return s.astype(str).str.upper().str.replace(r"\s+", "", regex=True)

                                code_series = _norm(qtbl[code_col])
                                name_series = qtbl[name_col].astype(str)
                                map_dict = dict(zip(code_series, name_series))

                                dim_comp_df["Dimension_label"] = (
                                    _norm(dim_comp_df["Dimension"])
                                    .map(map_dict)
                                    .fillna(dim_comp_df["Dimension"])
                                )
                            else:
                                dim_comp_df["Dimension_label"] = dim_comp_df["Dimension"]

                            break
                    else:
                        # Ù„Ùˆ Ù…Ø§ Ù„Ù‚ÙŠÙ†Ø§ ÙˆØ±Ù‚Ø© Questions
                        dim_comp_df["Dimension_label"] = dim_comp_df["Dimension"]

                    # ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„Ù†Ø³Ø¨
                    dim_comp_df["Score"] = dim_comp_df["Score"].round(1)

                                     # 4ï¸âƒ£ Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª
                    st.markdown("### ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù‡Ø§Øª")
                    st.dataframe(
                        dim_comp_df[["Dimension", "Dimension_label", "Ø§Ù„Ø¬Ù‡Ø©", "Score"]]
                        .rename(columns={
                            "Dimension": "Ø±Ù…Ø² Ø§Ù„Ø¨Ø¹Ø¯",
                            "Dimension_label": "Ø§Ø³Ù… Ø§Ù„Ø¨Ø¹Ø¯",
                            "Score": "Ø§Ù„Ù†Ø³Ø¨Ø© (%)"
                        })
                        .style.format({"Ø§Ù„Ù†Ø³Ø¨Ø© (%)": "{:.1f}%"}),
                        use_container_width=True,
                        hide_index=True
                    )

                    # 5ï¸âƒ£ Ø±Ø³Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© (Ù„ÙƒÙ„ Ø§Ù„Ø¬Ù‡Ø§Øª)
                    st.markdown("### ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù‡Ø§Øª")

                    # Ù†Ø±ØªØ¨ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø±Ù‚Ù…ÙŠ Dim1, Dim2, ...
                    dim_comp_df["Order"] = dim_comp_df["Dimension"].str.extract(r"(\d+)").astype(float)
                    dim_comp_df_sorted = dim_comp_df.sort_values(["Order", "Ø§Ù„Ø¬Ù‡Ø©"])

                    fig_all = px.bar(
                        dim_comp_df_sorted,
                        x="Dimension_label",
                        y="Score",
                        color="Ø§Ù„Ø¬Ù‡Ø©",
                        barmode="group",
                        text="Score",
                        title="Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¬Ù‡Ø§Øª ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"
                    )
                    fig_all.update_traces(texttemplate="%{text:.1f}%", textposition="outside")
                    fig_all.update_layout(
                        xaxis_title="Ø§Ù„Ø¨Ø¹Ø¯",
                        yaxis_title="Ø§Ù„Ù†ØªÙŠØ¬Ø© (%)",
                        yaxis=dict(range=[0, 100]),
                        xaxis_tickangle=-20,
                        legend=dict(orientation="h", y=-0.25)
                    )
                    st.plotly_chart(fig_all, use_container_width=True)

# =========================================================
# ØªØ­Ø³ÙŠÙ†Ø§Øª Ø´ÙƒÙ„ÙŠØ©
# =========================================================
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer, [data-testid="stFooter"] {opacity: 0.03 !important; height: 1px !important; overflow: hidden !important;}
    </style>
""", unsafe_allow_html=True)















































































